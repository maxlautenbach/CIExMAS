{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements-synthie.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"/ceph/mlautenb/synthIE/data\"\n",
    "MODELS_DIR=\"/ceph/mlautenb/synthIE/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mlautenb/miniconda3/envs/synthie/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "synthie_root = pathlib.Path('/home/mlautenb/SynthIE').resolve()\n",
    "ciexmas_root = pathlib.Path('/home/mlautenb/CIExMAS').resolve()\n",
    "sys.path.insert(0, str(synthie_root))\n",
    "sys.path.insert(0, str(ciexmas_root))\n",
    "\n",
    "\n",
    "\"\"\"Load the Model (downloaded in the ../data/models directory)\"\"\"\n",
    "from src.models import GenIEFlanT5PL\n",
    "\n",
    "ckpt_name = \"genie_base_sc.ckpt\"\n",
    "path_to_checkpoint = os.path.join(MODELS_DIR, ckpt_name)\n",
    "model = GenIEFlanT5PL.load_from_checkpoint(checkpoint_path=path_to_checkpoint)\n",
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load constrained decoding module\"\"\"\n",
    "from src.constrained_generation import IEConstrainedGeneration\n",
    "\n",
    "params = {}\n",
    "params['constrained_worlds_dir'] = os.path.join(DATA_DIR, \"constrained_worlds\")\n",
    "params['constrained_world_id'] = \"genie_t5_tokenizeable\" # specifies the folder name from which the constrained world is loaded\n",
    "params['identifier'] = \"genie_t5_tokenizeable\" # specifies the cache subfolder where the trie will be stored\n",
    "    \n",
    "params['path_to_trie_cache_dir'] = os.path.join(DATA_DIR, \".cache\")\n",
    "params['path_to_entid2name_mapping'] = os.path.join(DATA_DIR, \"id2name_mappings\", \"entity_mapping.jsonl\")\n",
    "params['path_to_relid2name_mapping'] = os.path.join(DATA_DIR, \"id2name_mappings\", \"relation_mapping.jsonl\")\n",
    "\n",
    "constraint_module = IEConstrainedGeneration.from_constrained_world(model=model, \n",
    "                                                                   linearization_class_id=model.hparams.linearization_class_id, \n",
    "                                                                   **params)\n",
    "\n",
    "model.constraint_module = constraint_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "path_to_entity_id2name_mapping = os.path.join(DATA_DIR, \"id2name_mappings\", \"entity_mapping.jsonl\")\n",
    "with jsonlines.open(path_to_entity_id2name_mapping) as reader:\n",
    "    entity_id2name_mapping = {obj[\"id\"]: obj[\"en_label\"] for obj in reader}\n",
    "\n",
    "path_to_relation_id2name_mapping = os.path.join(DATA_DIR, \"id2name_mappings\", \"relation_mapping.jsonl\")\n",
    "with jsonlines.open(path_to_relation_id2name_mapping) as reader:\n",
    "    relation_id2name_mapping = {obj[\"id\"]: obj[\"en_label\"] for obj in reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_id_by_name(entity_name, mapping):\n",
    "    return next(k for k, v in mapping.items() if v == entity_name)\n",
    "\n",
    "def get_relation_id_by_name(relation_name, mapping):\n",
    "    return next(k for k, v in mapping.items() if v == relation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90325446afd8449e9ec4d68785a561a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 27 files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 39666.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from helper_tools import parser\n",
    "\n",
    "DATASET = \"synthie_text\"\n",
    "SPLIT = \"test\"\n",
    "NUMBER_OF_SAMPLES = 50\n",
    "\n",
    "triple_df, entity_df, docs = parser.unified_parser(DATASET, SPLIT, NUMBER_OF_SAMPLES, upload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [03:32<00:00,  4.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "override_models_default_hf_generation_parameters = {\n",
    "    \"num_beams\": 10,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"return_dict_in_generate\": True,\n",
    "    \"output_scores\": True,\n",
    "    \"seed\": 123,\n",
    "    \"length_penalty\": 0.8\n",
    "}\n",
    "\n",
    "turtle_string_docs = dict()\n",
    "\n",
    "for i in tqdm(range(len(docs))):\n",
    "    target_doc = docs.iloc[i]\n",
    "    doc_id = target_doc[\"docid\"]\n",
    "    text = target_doc[\"text\"]\n",
    "    output = model.sample([text],\n",
    "                        convert_to_triplets=True,\n",
    "                        **override_models_default_hf_generation_parameters)\n",
    "    turtle_string = \"@prefix wd: <http://www.wikidata.org/entity/> .\\n\"\n",
    "    for triple in output['grouped_decoded_outputs'][0][0]:\n",
    "        turtle_string += f\"wd:{get_entity_id_by_name(triple[0], entity_id2name_mapping)} wdt:{get_relation_id_by_name(triple[1], relation_id2name_mapping)} wd:{get_entity_id_by_name(triple[2], entity_id2name_mapping)} .\\n\"\n",
    "    turtle_string_docs[doc_id] = turtle_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "pickle.dump(turtle_string_docs, open(f\"{ciexmas_root}/approaches/evaluation_logs/One_Agent/{DATASET}-{SPLIT}-{NUMBER_OF_SAMPLES}-evaluation_log-{os.getenv('LLM_MODEL_PROVIDER')}_{ckpt_name.split('.')[0]}-{datetime.now().strftime('%Y-%m-%d-%H%M')}.xlsx\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
