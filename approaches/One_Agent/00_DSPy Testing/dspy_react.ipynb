{
 "cells": [
  {
   "cell_type": "code",
   "id": "f7afdb13cc2bdacb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:24.977048Z",
     "start_time": "2025-06-02T09:22:16.963194Z"
    }
   },
   "source": [
    "import git\n",
    "import sys\n",
    "\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "sys.path.append(repo.working_dir)\n",
    "\n",
    "from helper_tools import parser\n",
    "\n",
    "triple_df, entity_df, docs = parser.synthie_parser(\"train_text\", 10)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:22:19,505 - INFO - Initializing llama-3.3-70b at Cerebras - 30.0 RPM\n",
      "2025-06-02 11:22:19,522 - INFO - Embeddings model bge-m3 initialized\n",
      "2025-06-02 11:22:19,530 - INFO - Langfuse handler initialized\n",
      "2025-06-02 11:22:19,538 - INFO - Langfuse client initialized\n",
      "2025-06-02 11:22:19,539 - INFO - Initializing Qdrant vector store\n",
      "2025-06-02 11:22:21,543 - INFO - Qdrant vector store initialized\n",
      "2025-06-02 11:22:21,615 - INFO - Qdrant description vector store initialized\n",
      "2025-06-02 11:22:21,683 - INFO - Qdrant example vector store initialized\n",
      "2025-06-02 11:22:21,976 - INFO - Dataset wikidata_predicates: exists, triple count: 53680\n",
      "2025-06-02 11:22:22,633 - INFO - Dataset wikidata_class_hierarchy: exists, triple count: 1612566\n",
      "2025-06-02 11:22:22,634 - INFO - Fuseki clients initialized\n",
      "2025-06-02 11:22:22,635 - INFO - SPARQL wrapper initialized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 27 files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4d3908ba3084b278b01fb9dd6b7f562"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 92794.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing entities for bulk upload to qdrant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing entities: 100%|██████████| 46/46 [00:01<00:00, 37.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new entities to upload. 46 entities were already in the database.\n",
      "Preparing predicates for bulk upload to qdrant...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing predicates: 100%|██████████| 26/26 [00:00<00:00, 38.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new predicates to upload. 26 predicates were already in the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e49dd33f8cfc8654",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:28.020226Z",
     "start_time": "2025-06-02T09:22:25.252514Z"
    }
   },
   "source": [
    "import os\n",
    "import dspy\n",
    "import git\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "repo = git.Repo(search_parent_directories=True).working_dir\n",
    "load_dotenv(repo + \".env\")\n",
    "\n",
    "lm = dspy.LM('openai/Meta-Llama-3.3-70B-Instruct', api_key=os.getenv(\"SAMBANOVA_API_KEY\"), api_base='https://api.sambanova.ai/v1')\n",
    "dspy.configure(lm=lm)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:28.037294Z",
     "start_time": "2025-06-02T09:22:28.032081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "import traceback\n",
    "from helper_tools.base_setup import label_vector_store, example_vector_store\n",
    "import re\n",
    "from qdrant_client.http import models\n",
    "\n",
    "def uri_search_tool(search_terms: List[str]):\n",
    "    \"\"\"Fetch URIs for search terms from the underlying knowledge graph. Each Search Term must be given as a string followed by one of the search modes in [] brackets:\n",
    "    [Q] - Entity Search\n",
    "    [P] - Property Search by Term\n",
    "    [X] - Property Search by Example Sentence\n",
    "\n",
    "    For example: {search_terms: [Angela Merkel[Q], CDU[Q], member of[P], Angela Merkel is member of CDU[X]]}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        search_response = \"\"\n",
    "\n",
    "        for term in search_terms:\n",
    "            # Parse search term and mode\n",
    "            mode = None\n",
    "            clean_term = term\n",
    "\n",
    "            # Extract mode from term using regex\n",
    "            if \"[\" in term and \"]\" in term:\n",
    "                mode_match = re.search(r'\\[([QPX])\\]', term)\n",
    "                if mode_match:\n",
    "                    mode = mode_match.group(1)\n",
    "                    clean_term = re.sub(r'\\[([QPX])\\]', '', term).strip()\n",
    "\n",
    "            # Default behavior if no mode is specified\n",
    "            if not mode:\n",
    "                # Assume it's a label search\n",
    "                results = label_vector_store.similarity_search_with_score(clean_term, k=3)\n",
    "                search_response += f'Most Similar Search Results for \"{clean_term}\" - Default Search Mode (LABEL):\\n'\n",
    "\n",
    "                for idx, (doc, sim_score) in enumerate(results):\n",
    "                    search_response += f\"  {idx+1}. Label: {doc.page_content}\\n\"\n",
    "                    search_response += f\"     URI: {doc.metadata['uri']}\\n\"\n",
    "                    search_response += f\"     Description: {doc.metadata['description']}\\n\"\n",
    "                search_response += \"\\n\"\n",
    "                continue\n",
    "\n",
    "            # Create filter condition if mode is Q or P\n",
    "            filter_condition = None\n",
    "            if mode in ['Q', 'P']:\n",
    "                filter_condition = models.Filter(\n",
    "                    must=[\n",
    "                        models.FieldCondition(\n",
    "                            key=\"metadata.type\",\n",
    "                            match=models.MatchValue(value=\"entity\" if mode == \"Q\" else \"predicate\")\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            # Perform search based on the mode\n",
    "            if mode in ['Q', 'P']:\n",
    "                # Search in labels with type filter\n",
    "                results = label_vector_store.similarity_search_with_score(\n",
    "                    clean_term,\n",
    "                    k=3,\n",
    "                    filter=filter_condition\n",
    "                )\n",
    "                search_response += f'Similar Search Results for \"{clean_term}\" - Search Mode [{mode}]:\\n'\n",
    "\n",
    "                for idx, (doc, sim_score) in enumerate(results):\n",
    "                    search_response += f\"  - Label: {doc.page_content}\\n\"\n",
    "                    search_response += f\"     URI: {doc.metadata['uri']}\\n\"\n",
    "                    search_response += f\"     Description: {doc.metadata['description']}\\n\"\n",
    "                    if doc.metadata.get(\"example\"):\n",
    "                        search_response += f\"     Example: {doc.metadata['example']}\\n\"\n",
    "\n",
    "            elif mode == 'X':\n",
    "                # Search in examples collection\n",
    "                results = example_vector_store.similarity_search_with_score(\n",
    "                    clean_term,\n",
    "                    k=3\n",
    "                )\n",
    "                search_response += f'Similar Search Results for \"{clean_term}\" - Search Mode [X]:\\n'\n",
    "\n",
    "                for idx, (doc, sim_score) in enumerate(results):\n",
    "                    search_response += f\"  - Label: {doc.metadata['label']}\\n\"\n",
    "                    search_response += f\"     URI: {doc.metadata['uri']}\\n\"\n",
    "                    search_response += f\"     Description: {doc.metadata['description']}\\n\"\n",
    "                    search_response += f\"     Example: {doc.page_content}\\n\"\n",
    "\n",
    "            search_response += \"\\n\"\n",
    "        return search_response\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"SYSTEM MESSAGE: Error occurred in URI search tool: {str(e)}\\n{traceback.format_exc()}\""
   ],
   "id": "1f84c6bb5a6fb5a4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:28.048539Z",
     "start_time": "2025-06-02T09:22:28.045529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dspy\n",
    "\n",
    "class cIEAgent(dspy.Signature):\n",
    "    \"\"\"You are an expert for closed information extraction (the extraction of triples using a given text, where the triples match an underlying knowledge graph.). You will be given a text and should extract triples out of it and map those triples onto the underlying knowledge graph.\n",
    "\n",
    "    You are given a list of tools to handle user request, and you should decide the right tool to use in order to fullfil users' request.\n",
    "    \"\"\"\n",
    "\n",
    "    text: str = dspy.InputField()\n",
    "    turtle_string: str = dspy.OutputField(\n",
    "        desc=(\n",
    "                \"Output of the extracted triples from the text. Format: Turtle. Restricted to wd: namespace. Usage of wdt: is prohibited.\"\n",
    "            )\n",
    "        )"
   ],
   "id": "8e7794d4a8866f4b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:28.061133Z",
     "start_time": "2025-06-02T09:22:28.056450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = dspy.ReAct(\n",
    "    cIEAgent,\n",
    "    tools = [\n",
    "        uri_search_tool\n",
    "    ]\n",
    ")"
   ],
   "id": "f47eaaeb2ceb6a56",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:28.951675Z",
     "start_time": "2025-06-02T09:22:28.068744Z"
    }
   },
   "cell_type": "code",
   "source": "result = agent(text=docs.iloc[0][\"text\"])",
   "id": "6b5a35083a7c7545",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:28.962461Z",
     "start_time": "2025-06-02T09:22:28.960322Z"
    }
   },
   "cell_type": "code",
   "source": "result.turtle_string",
   "id": "7e2025b85d16fdca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wd:Q18020434 wdt:P1366 wd:Q50839256 .\\nwd:Q50839256 wdt:P749 wd:Q59261 .\\nwd:Q50839256 wdt:P159 wd:Q393454 .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:22:28.977128Z",
     "start_time": "2025-06-02T09:22:28.974424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# noinspection PyTypeChecker\n",
    "for i in range(len([key for key in result.trajectory.keys() if key.startswith('thought_')])):\n",
    "    thought = result.trajectory.get(f'thought_{i}', '')\n",
    "    tool_name = result.trajectory.get(f'tool_name_{i}', '')\n",
    "    tool_args = result.trajectory.get(f'tool_args_{i}', '')\n",
    "    observation = result.trajectory.get(f'observation_{i}', '')\n",
    "\n",
    "    print(f\"Thought {i}: {thought}\\n\")\n",
    "    print(f\"Tool Name {i}: {tool_name}\")\n",
    "    print(f\"Tool Args {i}: {tool_args}\")\n",
    "    print(f\"Tool Output {i}: {observation}\\n{'-'*40}\")\n"
   ],
   "id": "4f640a47f131be38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 0: To extract triples from the given text and map them onto the underlying knowledge graph, we first need to identify key entities and their relationships. The text mentions the \"General Administration of Quality Supervision, Inspection and Quarantine,\" the \"State Administration for Market Regulation,\" and the \"State Council of the People's Republic of China.\" It also mentions the location of the headquarters, \"Haidian District, China.\" Our next step should be to find URIs for these entities in the knowledge graph.\n",
      "\n",
      "Tool Name 0: uri_search_tool\n",
      "Tool Args 0: {'search_terms': ['General Administration of Quality Supervision, Inspection and Quarantine[Q]', 'State Administration for Market Regulation[Q]', \"State Council of the People's Republic of China[Q]\", 'Haidian District, China[Q]']}\n",
      "Tool Output 0: Similar Search Results for \"General Administration of Quality Supervision, Inspection and Quarantine\" - Search Mode [Q]:\n",
      "  - Label: General_Administration_of_Quality_Supervision,_Inspection_and_Quarantine\n",
      "     URI: http://www.wikidata.org/entity/Q18020434\n",
      "     Description: predecessor of the State Administration for Market Regulation\n",
      "  - Label: State_Administration_for_Market_Regulation\n",
      "     URI: http://www.wikidata.org/entity/Q50839256\n",
      "     Description: ministry-level executive agency, under direct authority of the State Council of the People's Republic of China\n",
      "  - Label: Standard_Generalized_Markup_Language\n",
      "     URI: http://www.wikidata.org/entity/Q207819\n",
      "     Description: markup language\n",
      "\n",
      "Similar Search Results for \"State Administration for Market Regulation\" - Search Mode [Q]:\n",
      "  - Label: State_Administration_for_Market_Regulation\n",
      "     URI: http://www.wikidata.org/entity/Q50839256\n",
      "     Description: ministry-level executive agency, under direct authority of the State Council of the People's Republic of China\n",
      "  - Label: Government_agency\n",
      "     URI: http://www.wikidata.org/entity/Q327333\n",
      "     Description: organisational part of a government responsible for specific public services, such as health, judiciary, education, transportation, foreign affairs, etc\n",
      "  - Label: General_Administration_of_Quality_Supervision,_Inspection_and_Quarantine\n",
      "     URI: http://www.wikidata.org/entity/Q18020434\n",
      "     Description: predecessor of the State Administration for Market Regulation\n",
      "\n",
      "Similar Search Results for \"State Council of the People's Republic of China\" - Search Mode [Q]:\n",
      "  - Label: State_Council_of_the_People's_Republic_of_China\n",
      "     URI: http://www.wikidata.org/entity/Q59261\n",
      "     Description: chief administrative authority of the People's Republic of China\n",
      "  - Label: China\n",
      "     URI: http://www.wikidata.org/entity/Q148\n",
      "     Description: country in East Asia\n",
      "  - Label: Government_of_Russia\n",
      "     URI: http://www.wikidata.org/entity/Q1140115\n",
      "     Description: highest federal executive body in the Russian Federation, headed by the Prime Minister\n",
      "\n",
      "Similar Search Results for \"Haidian District, China\" - Search Mode [Q]:\n",
      "  - Label: Haidian_District\n",
      "     URI: http://www.wikidata.org/entity/Q393454\n",
      "     Description: district in Beijing, People's Republic of China\n",
      "  - Label: Hai_District\n",
      "     URI: http://www.wikidata.org/entity/Q1364658\n",
      "     Description: district of Tanzania\n",
      "  - Label: China\n",
      "     URI: http://www.wikidata.org/entity/Q148\n",
      "     Description: country in East Asia\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Thought 1: We have obtained the URIs for the key entities mentioned in the text: \"General Administration of Quality Supervision, Inspection and Quarantine,\" \"State Administration for Market Regulation,\" \"State Council of the People's Republic of China,\" and \"Haidian District, China.\" The next step is to extract the relationships between these entities based on the text and map them onto the knowledge graph. The text states that the \"General Administration of Quality Supervision, Inspection and Quarantine was replaced by the State Administration for Market Regulation\" and that the \"State Administration for Market Regulation\" is \"under the parent organization, the State Council of the People's Republic of China.\" It also mentions the location of the headquarters of the \"State Administration for Market Regulation\" as \"Haidian District, China.\" We need to find properties in the knowledge graph that correspond to these relationships, such as \"replaced by,\" \"parent organization,\" and \"headquarters location.\"\n",
      "\n",
      "Tool Name 1: uri_search_tool\n",
      "Tool Args 1: {'search_terms': ['replaced by[P]', 'parent organization[P]', 'headquarters location[P]', 'State Administration for Market Regulation is replaced by[X]', 'State Administration for Market Regulation is under the parent organization[X]', 'State Administration for Market Regulation headquarters location[X]']}\n",
      "Tool Output 1: Similar Search Results for \"replaced by\" - Search Mode [P]:\n",
      "  - Label: replaced by\n",
      "     URI: http://www.wikidata.org/entity/P1366\n",
      "     Description: other person or item which continues the item by replacing it in its role. Use P156 (\"followed by\") if the item is not replaced nor identical, but adds to the series (e.g. books in a series).\n",
      "     Example: Canada East replaced by Quebec\n",
      "  - Label: used by\n",
      "     URI: http://www.wikidata.org/entity/P1535\n",
      "     Description: item or concept that makes use of the subject (use sub-properties when appropriate)\n",
      "     Example: paintbrush used by painter\n",
      "  - Label: different from\n",
      "     URI: http://www.wikidata.org/entity/P1889\n",
      "     Description: item that is different from another item, with which it may be confused\n",
      "     Example: coup d'état different from Golpe de Estado\n",
      "\n",
      "Similar Search Results for \"parent organization\" - Search Mode [P]:\n",
      "  - Label: parent organization\n",
      "     URI: http://www.wikidata.org/entity/P749\n",
      "     Description: parent organization of an organization, opposite of subsidiaries (P355)\n",
      "     Example: Airbus parent organization Airbus SE\n",
      "  - Label: organizer\n",
      "     URI: http://www.wikidata.org/entity/P664\n",
      "     Description: person or institution organizing an event\n",
      "     Example: Eurovision Song Contest organizer European Broadcasting Union\n",
      "  - Label: chief operating officer\n",
      "     URI: http://www.wikidata.org/entity/P1789\n",
      "     Description: the chief operating officer of an organization\n",
      "     Example: Meta Platforms chief operating officer Sheryl Sandberg\n",
      "\n",
      "Similar Search Results for \"headquarters location\" - Search Mode [P]:\n",
      "  - Label: headquarters location\n",
      "     URI: http://www.wikidata.org/entity/P159\n",
      "     Description: specific location where an organisation's HQ is or has been located\n",
      "     Example: Wikimedia Foundation headquarters location San Francisco\n",
      "  - Label: location\n",
      "     URI: http://www.wikidata.org/entity/P276\n",
      "     Description: location of the item, physical object or event is within. In case of an administrative entity use P131. In case of a distinct terrain feature use P706.\n",
      "     Example: Mona Lisa location Salle des États, Louvre\n",
      "  - Label: work location\n",
      "     URI: http://www.wikidata.org/entity/P937\n",
      "     Description: location where persons or organisations were actively participating in employment, business or other work\n",
      "     Example: Joseph Stalin work location Moscow\n",
      "\n",
      "Similar Search Results for \"State Administration for Market Regulation is replaced by\" - Search Mode [X]:\n",
      "  - Label: replaced by\n",
      "     URI: http://www.wikidata.org/entity/P1366\n",
      "     Description: other person or item which continues the item by replacing it in its role. Use P156 (\"followed by\") if the item is not replaced nor identical, but adds to the series (e.g. books in a series).\n",
      "     Example: Canada East replaced by Quebec\n",
      "  - Label: follows\n",
      "     URI: http://www.wikidata.org/entity/P155\n",
      "     Description: immediately prior item in a series of which the subject is a part, preferably use as qualifier of P179 [if the subject has replaced the preceding item, e.g. political offices, use \"replaces\" (P1365)]\n",
      "     Example: April follows March\n",
      "  - Label: contains administrative territorial entity\n",
      "     URI: http://www.wikidata.org/entity/P150\n",
      "     Description: (list of) direct subdivisions of an administrative territorial entity\n",
      "     Example: United Kingdom contains administrative territorial entity England\n",
      "\n",
      "Similar Search Results for \"State Administration for Market Regulation is under the parent organization\" - Search Mode [X]:\n",
      "  - Label: parent organization\n",
      "     URI: http://www.wikidata.org/entity/P749\n",
      "     Description: parent organization of an organization, opposite of subsidiaries (P355)\n",
      "     Example: Airbus parent organization Airbus SE\n",
      "  - Label: applies to jurisdiction\n",
      "     URI: http://www.wikidata.org/entity/P1001\n",
      "     Description: the item (an institution, law, public office ...) or statement belongs to or applies to the value (a territorial jurisdiction: a country, state, municipality, ...)\n",
      "     Example: European Central Bank applies to jurisdiction European Union\n",
      "  - Label: intended public\n",
      "     URI: http://www.wikidata.org/entity/P2360\n",
      "     Description: intended audience or user of this work, product, object, or event\n",
      "     Example: school intended public child\n",
      "\n",
      "Similar Search Results for \"State Administration for Market Regulation headquarters location\" - Search Mode [X]:\n",
      "  - Label: headquarters location\n",
      "     URI: http://www.wikidata.org/entity/P159\n",
      "     Description: specific location where an organisation's HQ is or has been located\n",
      "     Example: Wikimedia Foundation headquarters location San Francisco\n",
      "  - Label: location\n",
      "     URI: http://www.wikidata.org/entity/P276\n",
      "     Description: location of the item, physical object or event is within. In case of an administrative entity use P131. In case of a distinct terrain feature use P706.\n",
      "     Example: Mona Lisa location Salle des États, Louvre\n",
      "  - Label: terminus location\n",
      "     URI: http://www.wikidata.org/entity/P609\n",
      "     Description: location of the terminus of a linear feature\n",
      "     Example: Oklahoma State Highway 325 terminus location New Mexico\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Thought 2: We have obtained the URIs for the key entities and the properties that correspond to the relationships between these entities. The next step is to use these URIs to construct triples that represent the information in the text. We can then use these triples to create a turtle string that represents the extracted information in a format that can be easily integrated into the knowledge graph.\n",
      "\n",
      "Tool Name 2: finish\n",
      "Tool Args 2: {}\n",
      "Tool Output 2: Completed.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:28:01.339114Z",
     "start_time": "2025-06-02T09:28:01.330890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = []\n",
    "\n",
    "# Gruppiere triples nach docid\n",
    "grouped_triples = triple_df.groupby(\"docid\")\n",
    "\n",
    "for i, doc in docs.iterrows():\n",
    "    docid = doc[\"docid\"]\n",
    "    text = doc[\"text\"]\n",
    "\n",
    "    # Liste der triples für diesen docid\n",
    "    turtle_triples = []\n",
    "\n",
    "    if docid in grouped_triples.groups:\n",
    "        group = grouped_triples.get_group(docid)\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            subject_uri = row[\"subject_uri\"].strip()\n",
    "            predicate_uri = row[\"predicate_uri\"].strip()\n",
    "            object_uri = row[\"object_uri\"].strip()\n",
    "            turtle_triples.append(f\"<{subject_uri}> <{predicate_uri}> <{object_uri}> .\")\n",
    "\n",
    "    # Alle Tripel zusammenfügen zu einem Turtle-String\n",
    "    turtle_string = \"\\n\".join(turtle_triples)\n",
    "\n",
    "    # Beispiel erstellen\n",
    "    dataset.append(dspy.Example(text=text, turtle_string=turtle_string).with_inputs(\"text\"))\n",
    "\n",
    "trainset = dataset\n"
   ],
   "id": "b2726a6edcb8c9f1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:28:02.375943Z",
     "start_time": "2025-06-02T09:28:02.373376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helper_tools.evaluation import evaluate_doc, calculate_scores_from_array, compare_turtle_strings\n",
    "\n",
    "\n",
    "def scoring(example, pred, trace=None):\n",
    "    values_array = compare_turtle_strings(predicted_turtle_string=pred.turtle_string, ground_truth_turtle_string=example.turtle_string)\n",
    "    return calculate_scores_from_array(values_array).loc[\"Triple\"][\"F1-Score\"]"
   ],
   "id": "e81396860e870730",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T09:38:14.336669Z",
     "start_time": "2025-06-02T09:28:02.878387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tp = dspy.MIPROv2(metric=scoring, auto=\"light\", num_threads=1)\n",
    "optimized_agent = tp.compile(agent, trainset=trainset, requires_permission_to_run=False)"
   ],
   "id": "46034ffd776ea4a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:28:02 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 20\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 3\n",
      "valset size: 8\n",
      "\n",
      "2025/06/02 11:28:02 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/06/02 11:28:02 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/06/02 11:28:02 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[92m11:28:02 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:02,884 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856484.3721714, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:04 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:04,539 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:04 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:04,539 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:04 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:04,540 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:06 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:06,648 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856487.7880847, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:07 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:07,920 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:07,921 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:07,922 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:07 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:07,933 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856489.1413867, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:09 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:09,251 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:09,252 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:09,254 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:10,371 - INFO - PyTorch version 2.6.0 available.\n",
      " 50%|█████     | 1/2 [00:08<00:08,  8.02s/it]\u001B[92m11:28:10 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:10,906 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856492.0353465, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:12 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:12,223 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:12,224 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:12,226 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:12 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:12,914 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856493.9065654, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:14,064 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:14,065 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:14,067 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:14 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:14,077 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856495.2281868, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:15 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:15,395 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:15,396 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:15,397 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.02s/it]\n",
      "2025/06/02 11:28:27 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/06/02 11:28:27 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "\u001B[92m11:28:27 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:27,869 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856509.7594998, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:29 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:29,851 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:29 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:29,853 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:29 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:29,855 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:29 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:29,862 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856510.673396, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:30 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:30,809 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:30,811 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:30,812 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:28:30 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=3 instructions...\n",
      "\n",
      "\u001B[92m11:28:30 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:30,824 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856512.3388171, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:32 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:32,430 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:32,432 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:32,433 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:32 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:32,444 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856514.6905148, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:34 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:34,783 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:34,785 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:34,796 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:34,851 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856517.0622737, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:37 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:37,205 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:37,206 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:37,206 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:37 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:37,211 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856518.8775492, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:39 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:39,050 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:39,051 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:39,052 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:39 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:39,063 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856521.3673632, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:41 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:41,507 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:41,508 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:41,509 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:41 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:41,517 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856523.8276434, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:43 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:43,965 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:43 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:43,966 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:43 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:43,968 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:43 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:43,976 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856526.2222755, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:46 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:46,314 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:46,315 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:46,317 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:46 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:46,325 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856527.9960723, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:48 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:48,086 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:48,087 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:48,089 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:48 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:48,097 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856529.63522, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:49 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:49,747 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:49,748 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:49,750 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:49 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:49,758 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856531.0052834, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:51 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:51,133 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:51,134 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:51,136 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:51 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:51,144 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856532.96023, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:53 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:53,052 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:53,053 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:53,055 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:53 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:53,062 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856535.354357, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:55 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:55,445 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:55,446 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:55,448 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:55 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:55,456 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856538.2577076, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:28:58 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:28:58,403 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:28:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:58,404 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:28:58,406 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:28:58 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:28:58,413 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856540.5541427, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:00 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:00,654 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:00,654 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:00,655 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:00 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:00,659 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856543.3724363, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:03 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:03,524 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:03,525 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:03,527 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:03 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:03,534 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856545.8478296, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:05 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:05,938 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:05,940 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:05,941 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: 0: You are an expert for closed information extraction (the extraction of triples using a given text, where the triples match an underlying knowledge graph.). You will be given a text and should extract triples out of it and map those triples onto the underlying knowledge graph.\n",
      "\n",
      "You are given a list of tools to handle user request, and you should decide the right tool to use in order to fullfil users' request.\n",
      "\n",
      "You are an Agent. In each episode, you will be given the fields `text` as input. And you can see your past trajectory so far.\n",
      "Your goal is to use one or more of the supplied tools to collect any necessary information for producing `turtle_string`.\n",
      "\n",
      "To do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\n",
      "After each tool call, you receive a resulting observation, which gets appended to your trajectory.\n",
      "\n",
      "When writing next_thought, you may reason about the current situation and plan for future steps.\n",
      "When selecting the next_tool_name and its next_tool_args, the tool must be one of:\n",
      "\n",
      "(1) uri_search_tool, whose description is <desc>Fetch URIs for search terms from the underlying knowledge graph. Each Search Term must be given as a string followed by one of the search modes in [] brackets:      [Q] - Entity Search      [P] - Property Search by Term      [X] - Property Search by Example Sentence        For example: {search_terms: [Angela Merkel[Q], CDU[Q], member of[P], Angela Merkel is member of CDU[X]]}      </desc>. It takes arguments {'search_terms': {'items': {'type': 'string'}, 'type': 'array'}} in JSON format.\n",
      "(2) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `turtle_string`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a knowledge graph expert tasked with extracting triples from a given text and mapping them onto an underlying knowledge graph. You will be given a text and should extract triples out of it and map those triples onto the underlying knowledge graph. Your goal is to use one or more of the supplied tools, including the `uri_search_tool` and the `finish` tool, to collect any necessary information for producing a `turtle_string` that represents the extracted triples in Turtle format. To do this, you will interleave your thoughts, the next tool to use, and the arguments for that tool in each turn, and also when finishing the task. After each tool call, you will receive a resulting observation that gets appended to your trajectory. When writing your thoughts, you may reason about the current situation and plan for future steps. When selecting the next tool and its arguments, ensure that the tool is one of the supplied options and that the arguments are in the correct format.\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are an expert for closed information extraction, tasked with extracting triples from a given text and mapping them onto an underlying knowledge graph. Your goal is to use one or more of the supplied tools, including uri_search_tool and finish, to collect necessary information for producing a turtle_string. \n",
      "\n",
      "To begin, analyze the input text to identify key entities and their relationships. Then, decide which tool to use first. If you need to find URIs for entities or relationship types in the knowledge graph, use the uri_search_tool by providing search terms followed by the appropriate search mode in brackets (e.g., [Q] for Entity Search, [P] for Property Search by Term). \n",
      "\n",
      "After each tool call, you will receive a resulting observation that will be appended to your trajectory. Use this information to plan your next steps, which may include additional uri_search_tool calls or finally marking the task as complete with the finish tool. \n",
      "\n",
      "When selecting the next_tool_name and its next_tool_args, ensure the tool is one of the provided options and that the arguments are in the correct JSON format. For example, uri_search_tool requires {'search_terms': ['term1[Q]', 'term2[P]']}.\n",
      "\n",
      "By iteratively using these tools and reasoning about the current situation, your objective is to construct triples that accurately represent the relationships between entities in the text, according to the underlying knowledge graph, and then signal the completion of the task.\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 1:\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: 0: You are an expert for closed information extraction (the extraction of triples using a given text, where the triples match an underlying knowledge graph.). You will be given a text and should extract triples out of it and map those triples onto the underlying knowledge graph.\n",
      "\n",
      "You are given a list of tools to handle user request, and you should decide the right tool to use in order to fullfil users' request.\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a critical component in a high-stakes information extraction system, responsible for extracting triples from a given text and mapping them onto an underlying knowledge graph. The success of this system directly impacts the accuracy of a national intelligence agency's database, which is used to inform critical decisions regarding national security and international relations. \n",
      "\n",
      "Given a text, you must identify key entities and their relationships, and then use the provided tools, specifically the `uri_search_tool`, to find URIs for these entities and relationship types in the knowledge graph. With the URIs obtained, you will construct triples representing the relationships between the entities as described in the text. The triples must be based on the entities and relationships identified, and they must be formatted in Turtle format, restricted to the `wd:` namespace, with the usage of `wdt:` prohibited.\n",
      "\n",
      "You will interleave your reasoning with tool calls, starting with identifying entities and relationships, then using the `uri_search_tool` to find URIs, and finally constructing the triples. Once you have all the necessary information, you will mark the task as complete using the `finish` tool.\n",
      "\n",
      "The text you need to process is: \"The General Administration of Quality Supervision, Inspection and Quarantine was replaced by the State Administration for Market Regulation and is a government agency under the parent organization, the State Council of the People's Republic of China. Its headquarters is located in Haidian District, China.\"\n",
      "\n",
      "You have two tools at your disposal:\n",
      "1. `uri_search_tool`: Fetches URIs for search terms from the underlying knowledge graph. Each search term must be given as a string followed by one of the search modes in [] brackets: [Q] for Entity Search, [P] for Property Search by Term, and [X] for Property Search by Example Sentence.\n",
      "2. `finish`: Marks the task as complete, signaling that all information for producing the output, i.e., the `turtle_string`, is now available to be extracted.\n",
      "\n",
      "Your goal is to use these tools effectively to extract the triples from the given text and represent them in Turtle format. The fate of the national intelligence agency's database, and by extension, the country's security and international standing, rests on your ability to accurately and efficiently complete this task.\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a knowledge graph engineer tasked with extracting triples from a given text and mapping them onto an underlying knowledge graph. You will be given a text and should use the provided tools to identify key entities and their relationships, and then construct triples that represent these relationships. Your goal is to use one or more of the supplied tools, including the `uri_search_tool`, to collect any necessary information for producing the output triples in Turtle format. To do this, you will interleave your thoughts, the tools you choose to use, and the arguments for those tools in each turn, and also when finishing the task. After each tool call, you will receive a resulting observation, which will be appended to your trajectory. When writing your thoughts, you may reason about the current situation and plan for future steps. When selecting the next tool and its arguments, the tool must be one of the provided options. You should continue this process until you have all the necessary information to construct the output triples and mark the task as complete using the `finish` tool.\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/06/02 11:29:05 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 20 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:05 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:05,961 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856547.4672709, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:07 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:07,619 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:07,620 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:07,621 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:08 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:08,331 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856549.3410866, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:09 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:09,431 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:09,432 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:09,433 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:09 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:09,444 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856550.9965363, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:11 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:11,087 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:11,089 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:11,090 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 1 (44.4%):  12%|█▎        | 1/8 [00:05<00:41,  5.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:11 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:11,908 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856553.0868905, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:13 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:13,178 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:13 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:13,179 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:13 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:13,180 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:13 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:13,539 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856554.6909776, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:14,782 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:14,783 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:14,785 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:14 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:14,811 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856556.2478123, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:16 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:16,427 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:16,429 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:16,430 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:29:16 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The 2003 Triple J Hottest 100 was determined by the Triple J Hottest 100. It followed the 2002 edition and was followed by the 2004 edition. It is an instance of a record chart.', 'turtle_string': '<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P459> <http://www.wikidata.org/entity/Q17036134> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P155> <http://www.wikidata.org/entity/Q7843427> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P156> <http://www.wikidata.org/entity/Q7843429> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q373899> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 4 of <>:\n",
      "Bad syntax (Prefix \"rdf:\" not bound) at ^ in:\n",
      "\"...b' wdt: <http://www.wikidata.org/prop/direct/> .\\n\\nwd:Q7843428 '^b'rdf:type wd:Q373899 .\\nwd:Q7843428 wd:P156 wd:Q7843429 .\\nwd:Q'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 1 (44.4%):  25%|██▌       | 2/8 [00:10<00:30,  5.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:16 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:16,445 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856557.3319483, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:17 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:17,423 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:17 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:17,424 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:17 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:17,426 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:17 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:17,623 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856558.721316, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:18 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:18,813 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:18,814 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:18,816 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:19 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:19,099 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856560.1213534, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:20 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:20,215 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:20 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:20,216 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:20 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:20,218 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:20 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:20,644 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856561.6442654, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:21 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:21,752 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:21,754 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:21,756 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:22 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:22,021 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856563.043451, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:23 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:23,135 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:23,136 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:23,138 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:23 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:23,148 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856564.0808744, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:24 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:24,172 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:24,174 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:24,175 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:29:24 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The NHL Stadium Series is a sport that consists of ice hockey.', 'turtle_string': '<http://www.wikidata.org/entity/Q17487840> <http://www.wikidata.org/entity/P641> <http://www.wikidata.org/entity/Q41466> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q17487840 wdt:P641 wd:Q41466 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 1 (44.4%):  38%|███▊      | 3/8 [00:18<00:31,  6.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:24 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:24,191 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856565.2242477, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:25 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:25,316 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:25 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:25,317 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:25 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:25,318 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:25 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:25,611 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856566.8297613, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:26 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:26,973 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:26,974 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:26,975 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:26 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:26,986 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856568.2150233, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:28 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:28,407 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:28,408 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:28,410 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:29:28 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Cerro Prieto is located in Mexico.', 'turtle_string': '<http://www.wikidata.org/entity/Q5064965> <http://www.wikidata.org/entity/P17> <http://www.wikidata.org/entity/Q96> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q5064965 wdt:P131 wd:Q96 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 1 (44.4%):  50%|█████     | 4/8 [00:22<00:21,  5.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:28 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:28,424 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856569.4727426, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:29 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:29,637 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:29 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:29,638 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:29 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:29,640 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:30 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:30,229 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856571.6635933, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:31 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:31,755 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:31,756 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:31,758 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:32 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:32,250 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856574.1077828, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:34 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:34,199 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:34,201 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:34,202 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:34,926 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856577.1315382, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:37 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:37,317 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:37,318 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:37,321 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:38 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:38,060 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856579.8414779, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:39 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:39,932 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:39,933 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:39,935 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:39 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:39,946 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856581.97245, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:42 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:42,129 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:42,130 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:42,131 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.61 / 2 (30.6%):  50%|█████     | 4/8 [00:38<00:21,  5.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:43 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.61 / 2 (30.6%):  62%|██████▎   | 5/8 [00:38<00:27,  9.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:29:43,976 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856585.2800865, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:45 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:45,404 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:45 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:45,404 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:45 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:45,405 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:45 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:45,703 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856586.74928, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:46 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:46,892 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:46,893 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:46,894 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:47 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:47,176 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856588.124158, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:48 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:48,273 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:48,274 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:48,275 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:48 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:48,286 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856589.2338529, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:49 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:49,325 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:49,327 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:49,329 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:29:49 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Vettaikaaran (2009 film) was originally written in the Tamil language, with B. Babusivan as the screenwriter.', 'turtle_string': '<http://www.wikidata.org/entity/Q3531049> <http://www.wikidata.org/entity/P364> <http://www.wikidata.org/entity/Q5885> .\\n<http://www.wikidata.org/entity/Q3531049> <http://www.wikidata.org/entity/P58> <http://www.wikidata.org/entity/Q25553837> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q3531049 wdt:P58 wd:Q25553837 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.61 / 2 (30.6%):  75%|███████▌  | 6/8 [00:43<00:15,  7.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:49 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:49,340 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856590.283584, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:50 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:50,376 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:50,378 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:50,380 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:50 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:50,840 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856591.7723303, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:51 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:51,962 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:51,964 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:51,966 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:51 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:51,976 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856593.799169, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:53 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:53,906 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:53,908 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:53,910 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:29:53 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Green economy is a subclass of Environmental economics, which studies the Natural environment and is different from Ecological economics. Environmental economics is itself a subclass of Economics.', 'turtle_string': '<http://www.wikidata.org/entity/Q598188> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q753291> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P2578> <http://www.wikidata.org/entity/Q43619> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P1889> <http://www.wikidata.org/entity/Q1049066> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q8134> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q598188 wdt:P279 wd:Q753291 .\\nwd:Q753291 wdt:P279 wd:Q813'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.61 / 2 (30.6%):  75%|███████▌  | 6/8 [00:47<00:15,  7.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:53 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.61 / 2 (30.6%):  88%|████████▊ | 7/8 [00:47<00:06,  6.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:29:53,924 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856594.8220353, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:54 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:54,914 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:54,916 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:54,917 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:55 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:55,233 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856596.4837937, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:56 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:56,673 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:56,674 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:56,678 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:57 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:57,051 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856597.9640791, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:58 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:58,104 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:58,106 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:58,108 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:58 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:58,122 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856599.1077237, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:29:59 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:29:59,232 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:29:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:59,233 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:29:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:29:59,235 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:29:59 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Abhishek Pictures is a film production company based in Hyderabad.', 'turtle_string': '<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q11424> .\\n<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P159> <http://www.wikidata.org/entity/Q1361> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q27958422 wdt:P131 wd:Q1361 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.61 / 2 (30.6%): 100%|██████████| 8/8 [00:53<00:00,  6.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:29:59 INFO dspy.evaluate.evaluate: Average Metric: 0.6111111111111112 / 8 (7.6%)\n",
      "2025/06/02 11:29:59 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 7.64\n",
      "\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/06/02 11:29:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:29:59 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:29:59,281 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856600.2273328, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:00 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:00,320 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:00,321 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:00,323 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:00 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:00,894 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856601.7986896, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:01 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:01,889 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:01,891 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:01,892 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:01 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:01,908 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856603.6836905, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:03 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:03,840 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:03,842 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:03,844 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:30:03 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The Ruger Bearcat is a Trigger (firearms) manufactured by Sturm, Ruger & Co. in the United States. It uses .22 Long Rifle rimfire ammunition, which is different from .22 Long.', 'turtle_string': '<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P739> <http://www.wikidata.org/entity/Q158715> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q336751> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P495> <http://www.wikidata.org/entity/Q30> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P176> <http://www.wikidata.org/entity/Q1508526> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q1289462> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P1889> <http://www.wikidata.org/entity/Q1056993> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P495> <http://www.wikidata.org/entity/Q30> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\n@prefix wd: <http://www.wikidata.org/entity/> .\\n@p'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  12%|█▎        | 1/8 [00:04<00:32,  4.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:03 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:03,864 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856604.841241, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:04 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:04,933 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:04 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:04,934 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:04 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:04,936 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:05 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:05,487 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856606.5540543, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:06 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:06,707 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:06,709 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:06,710 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:06 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:06,728 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856608.0181742, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:08 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:08,141 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:08,143 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:08,145 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):  25%|██▌       | 2/8 [00:10<00:31,  5.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:09 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:09,508 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856610.39424, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:10 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:10,487 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:10,488 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:10,489 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:10 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:10,850 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856612.3506956, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:12 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:12,542 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:12,543 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:12,545 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:12 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:12,560 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856614.5096886, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:14,692 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:14,694 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:14,695 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 2 (0.0%):  38%|███▊      | 3/8 [00:15<00:26,  5.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:14 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:14,973 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856615.8135855, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:15 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:15,923 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:15,924 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:15,926 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:16 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:16,267 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856617.4504774, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:17 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:17,542 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:17 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:17,544 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:17 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:17,546 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:17 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:17,554 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856618.97422, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:19 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:19,129 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:19 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:19,131 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:19 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:19,132 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 3 (0.0%):  50%|█████     | 4/8 [00:20<00:19,  4.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:19 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:19,394 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856620.4577374, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:20 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:20,550 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:20 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:20,552 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:20 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:20,554 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:21 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:21,467 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856622.4439583, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:22 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:22,534 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:22 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:22,535 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:22 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:22,537 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:22 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:22,547 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856624.3640852, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:24 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:24,525 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:24,529 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:24,532 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:30:24 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Swedish Open Cultural Heritage is a project developed by the Swedish National Heritage Board, which is mainly focused on cultural heritage. It produces Resource Description Framework as its product or material and uses XML, JSON, and JSON-LD as its file formats. XML was inspired by Standard Generalized Markup Language.', 'turtle_string': '<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2115> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2063> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P921> <http://www.wikidata.org/entity/Q210272> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P178> <http://www.wikidata.org/entity/Q631844> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q54872> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q6108942> .\\n<http://www.wikidata.org/entity/Q2115> <http://www.wikidata.org/entity/P941> <http://www.wikidata.org/entity/Q207819> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\nwd:Q7654799 wdt:P112 wd:Q631844 .\\nwd:Q7654799 wdt:'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 3 (0.0%):  50%|█████     | 4/8 [00:25<00:19,  4.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:24 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 3 (0.0%):  62%|██████▎   | 5/8 [00:25<00:15,  5.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:30:24,548 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856625.9131277, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:26 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:26,061 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:26,063 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:26,064 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:26 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:26,530 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856628.6182203, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:28 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:28,722 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:28,724 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:28,726 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:29 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:29,019 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856630.2498257, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:30 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:30,364 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:30,366 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:30,368 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:30 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:30,378 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856631.5628507, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:31 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:31,657 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:31,658 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:31,660 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.50 / 4 (12.5%):  75%|███████▌  | 6/8 [00:32<00:11,  5.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:32 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:32,064 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856633.0350966, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:33 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:33,127 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:33 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:33,129 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:33 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:33,130 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:33 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:33,734 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856634.7124076, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:34 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:34,804 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:34,806 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:34,808 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:34,820 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856635.9417543, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:36,033 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:36,034 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:36,036 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.50 / 5 (10.0%):  88%|████████▊ | 7/8 [00:37<00:05,  5.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:37 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:37,010 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856637.8463516, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:37 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:37,938 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:37,940 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:37,942 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:38 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:38,308 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856639.76326, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:39 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:39,855 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:39,857 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:39,864 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:40 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:40,251 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856641.2952795, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:41 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:41,420 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:41,422 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:41,424 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:41 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:41,438 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856642.591775, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:42 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:42,683 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:42,684 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:42,686 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:30:42 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Abhishek Pictures is a film production company based in Hyderabad.', 'turtle_string': '<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q11424> .\\n<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P159> <http://www.wikidata.org/entity/Q1361> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q27958422 wdt:P31 wd:Q4830453 ;\\n                   wdt:P1'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.50 / 5 (10.0%): 100%|██████████| 8/8 [00:43<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:30:42 INFO dspy.evaluate.evaluate: Average Metric: 0.5 / 8 (6.2%)\n",
      "2025/06/02 11:30:42 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 6.25 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 11:30:42 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25]\n",
      "2025/06/02 11:30:42 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 7.64\n",
      "2025/06/02 11:30:42 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:30:42 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:43 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:43,262 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856644.322239, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:44 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:44,493 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:44,495 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:44,497 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  12%|█▎        | 1/8 [00:02<00:20,  2.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:46 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:46,141 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856647.4129472, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:47 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:47,529 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:47 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:47,531 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:47 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:47,532 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.04 / 2 (52.2%):  25%|██▌       | 2/8 [00:05<00:16,  2.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:48 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:48,489 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856649.5920613, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:49 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:49,715 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:49,717 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:49,718 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.04 / 3 (34.8%):  38%|███▊      | 3/8 [00:07<00:11,  2.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:50 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:50,282 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856651.3517194, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:51 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:51,456 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:51,458 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:51,460 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.04 / 4 (26.1%):  50%|█████     | 4/8 [00:09<00:08,  2.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:52 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:52,625 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856655.2741463, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:55 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:55,413 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:55,414 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:55,416 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.81 / 5 (36.3%):  62%|██████▎   | 5/8 [00:14<00:09,  3.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:30:57 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:30:57,966 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856659.6975636, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:30:59 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:30:59,788 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:30:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:59,791 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:30:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:30:59,792 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.31 / 6 (38.6%):  75%|███████▌  | 6/8 [00:17<00:06,  3.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:00 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:00,770 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856662.4654796, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:02 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:02,619 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:02 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:02,621 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:02 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:02,622 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.81 / 7 (40.2%):  88%|████████▊ | 7/8 [00:20<00:03,  3.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:03 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:03,733 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856665.012493, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:05 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:05,181 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:05,182 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:05,184 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.31 / 8 (41.4%): 100%|██████████| 8/8 [00:22<00:00,  2.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:31:05 INFO dspy.evaluate.evaluate: Average Metric: 3.3136752136752134 / 8 (41.4%)\n",
      "2025/06/02 11:31:05 INFO dspy.teleprompt.mipro_optimizer_v2: \u001B[92mBest full score so far!\u001B[0m Score: 41.42\n",
      "2025/06/02 11:31:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 41.42 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/06/02 11:31:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42]\n",
      "2025/06/02 11:31:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:31:05 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:31:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:05 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:05,565 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856666.5346348, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:06 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:06,715 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:06,717 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:06,719 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:07 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:07,261 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856668.3425922, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:08 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:08,455 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:08,456 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:08,458 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:08 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:08,468 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856669.6103077, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:09 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:09,700 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:09,701 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:09,702 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:31:09 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The Ruger Bearcat is a Trigger (firearms) manufactured by Sturm, Ruger & Co. in the United States. It uses .22 Long Rifle rimfire ammunition, which is different from .22 Long.', 'turtle_string': '<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P739> <http://www.wikidata.org/entity/Q158715> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q336751> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P495> <http://www.wikidata.org/entity/Q30> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P176> <http://www.wikidata.org/entity/Q1508526> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q1289462> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P1889> <http://www.wikidata.org/entity/Q1056993> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P495> <http://www.wikidata.org/entity/Q30> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\nwd:Q7378530 wdt:P176 wd:Q1508526 .\\nwd:Q7378530 wdt'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  12%|█▎        | 1/8 [00:04<00:29,  4.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:09 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:09,719 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856670.7943435, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:10 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:10,887 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:10,889 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:10,891 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:11 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:11,427 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856672.5182388, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:12 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:12,653 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:12,654 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:12,658 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:12 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:12,674 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856674.1152968, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:14,207 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:14,209 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:14,211 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:31:14 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The 2003 Triple J Hottest 100 was determined by the Triple J Hottest 100. It followed the 2002 edition and was followed by the 2004 edition. It is an instance of a record chart.', 'turtle_string': '<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P459> <http://www.wikidata.org/entity/Q17036134> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P155> <http://www.wikidata.org/entity/Q7843427> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P156> <http://www.wikidata.org/entity/Q7843429> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q373899> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\n@prefix wd: <http://www.wikidata.org/entity/> .\\n@p'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  25%|██▌       | 2/8 [00:08<00:26,  4.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:14 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:14,233 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856675.2106557, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:15 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:15,320 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:15,322 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:15,323 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:15 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:15,645 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856677.2976067, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:17 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:17,469 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:17 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:17,470 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:17 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:17,474 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:17 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:17,495 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856678.765188, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:18 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:18,857 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:18,859 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:18,860 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):  25%|██▌       | 2/8 [00:13<00:26,  4.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:19 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):  38%|███▊      | 3/8 [00:13<00:23,  4.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:31:19,124 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856679.9531226, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:20 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:20,045 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:20 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:20,047 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:20 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:20,048 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:20 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:20,354 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856681.4554064, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:21 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:21,566 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:21,568 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:21,570 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:21 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:21,589 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856683.409446, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:23 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:23,502 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:23,504 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:23,506 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:31:23 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Cerro Prieto is located in Mexico.', 'turtle_string': '<http://www.wikidata.org/entity/Q5064965> <http://www.wikidata.org/entity/P17> <http://www.wikidata.org/entity/Q96> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q5064965 wdt:P131 wd:Q96 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):  50%|█████     | 4/8 [00:17<00:18,  4.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:23 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:23,528 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856684.590442, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:24 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:24,738 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:24,739 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:24,741 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:25 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:25,671 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856687.012821, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:27 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:27,195 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:27 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:27,197 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:27 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:27,199 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:27 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:27,212 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856691.0623837, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:31 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:31,189 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:31,191 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:31,193 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:31:31 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Swedish Open Cultural Heritage is a project developed by the Swedish National Heritage Board, which is mainly focused on cultural heritage. It produces Resource Description Framework as its product or material and uses XML, JSON, and JSON-LD as its file formats. XML was inspired by Standard Generalized Markup Language.', 'turtle_string': '<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2115> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2063> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P921> <http://www.wikidata.org/entity/Q210272> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P178> <http://www.wikidata.org/entity/Q631844> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q54872> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q6108942> .\\n<http://www.wikidata.org/entity/Q2115> <http://www.wikidata.org/entity/P941> <http://www.wikidata.org/entity/Q207819> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\n@prefix wd: <http://www.wikidata.org/entity/> .\\n@p'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n",
      "\u001B[92m11:31:31 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):  62%|██████▎   | 5/8 [00:25<00:16,  5.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:31:31,208 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856692.1444132, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:32 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:32,314 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:32,315 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:32,317 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:32 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:32,820 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856693.991203, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:34 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:34,082 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:34,083 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:34,084 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:34,099 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856695.4368076, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:35 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:35,592 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:35 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:35,594 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:35 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:35,595 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:31:35 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Vettaikaaran (2009 film) was originally written in the Tamil language, with B. Babusivan as the screenwriter.', 'turtle_string': '<http://www.wikidata.org/entity/Q3531049> <http://www.wikidata.org/entity/P364> <http://www.wikidata.org/entity/Q5885> .\\n<http://www.wikidata.org/entity/Q3531049> <http://www.wikidata.org/entity/P58> <http://www.wikidata.org/entity/Q25553837> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\nwd:Q3531049 wdt:P407 wd:Q5885 ;\\n         wdt:P58 w'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):  62%|██████▎   | 5/8 [00:30<00:16,  5.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:35 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):  75%|███████▌  | 6/8 [00:30<00:10,  5.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:31:35,609 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856696.5452936, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:36,637 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:36,639 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:36,640 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:37 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:37,249 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856698.2186718, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:38 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:38,353 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:38 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:38,354 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:38 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:38,355 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:38 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:38,366 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856699.5095108, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:39 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:39,685 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:39,686 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:39,687 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.57 / 2 (28.6%):  75%|███████▌  | 6/8 [00:34<00:10,  5.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:40 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:40,060 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.57 / 2 (28.6%):  88%|████████▊ | 7/8 [00:34<00:04,  4.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856701.133908, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:41 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:41,226 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:41,227 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:41,229 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:41 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:41,529 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856702.7944033, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:42 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:42,965 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:42,967 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:42,970 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:43 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:43,268 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856704.7160316, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:44 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:44,807 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:44,808 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:44,809 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:44 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:44,822 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856706.691366, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:46 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:46,782 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:46,783 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:46,785 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:31:46 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Abhishek Pictures is a film production company based in Hyderabad.', 'turtle_string': '<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q11424> .\\n<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P159> <http://www.wikidata.org/entity/Q1361> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\n@prefix wd: <http://www.wikidata.org/entity/> .\\n@p'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.57 / 2 (28.6%): 100%|██████████| 8/8 [00:41<00:00,  5.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:31:46 INFO dspy.evaluate.evaluate: Average Metric: 0.5714285714285715 / 8 (7.1%)\n",
      "2025/06/02 11:31:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 7.14 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 11:31:46 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14]\n",
      "2025/06/02 11:31:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:31:46 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:31:46 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:46 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:46,815 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856708.1745725, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:48 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:48,291 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:48,293 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:48,294 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:48 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:48,898 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856709.8920128, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:49 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:49,985 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:49,987 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:49,988 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:50 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:50,003 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856711.2138405, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:51 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:51,359 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:51,361 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:51,363 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):   0%|          | 0/8 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:52 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  12%|█▎        | 1/8 [00:05<00:39,  5.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:31:52,432 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856713.4747934, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:53 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:53,614 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:53,616 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:53,617 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:54 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:54,105 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856715.058084, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:55 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:55,150 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:55,152 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:55,153 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:55 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:55,166 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856716.4460106, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:56 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:56,585 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:56,586 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:56,588 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.10 / 2 (55.0%):  25%|██▌       | 2/8 [00:10<00:31,  5.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:31:57 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:57,329 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856718.209281, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:31:58 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:31:58,300 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:31:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:58,302 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:31:58,305 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:31:58 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:31:58,617 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856720.0030396, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:00 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:00,167 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:00,169 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:00,170 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:00 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:00,466 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856721.6447682, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:01 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:01,806 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:01,808 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:01,809 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:01 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:01,829 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856723.3964674, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:03 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:03,550 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:03,551 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:03,553 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.10 / 3 (36.7%):  25%|██▌       | 2/8 [00:16<00:31,  5.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:03 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.10 / 3 (36.7%):  38%|███▊      | 3/8 [00:16<00:28,  5.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:32:03,798 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856725.0361586, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:05 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:05,130 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:05,131 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:05,133 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:05 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:05,372 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856726.182492, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:06 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:06,272 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:06,273 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:06,274 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:06 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:06,408 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856727.395441, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:07 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:07,526 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:07,528 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:07,529 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:07 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:07,549 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856728.5159092, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:08 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:08,670 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:08,671 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:08,673 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.10 / 4 (27.5%):  50%|█████     | 4/8 [00:22<00:22,  5.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:08 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:08,926 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856730.5077925, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:10 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:10,612 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:10,613 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:10,615 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:11 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:11,532 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856732.6731744, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:12 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:12,865 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:12,867 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:12,868 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:13 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:13,482 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856735.5319777, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:15 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:15,628 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:15,630 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:15,632 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:15 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:15,647 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856738.1026452, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:18 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:18,194 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:18,196 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:18,197 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.25 / 5 (25.1%):  50%|█████     | 4/8 [00:34<00:22,  5.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:20 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.25 / 5 (25.1%):  62%|██████▎   | 5/8 [00:34<00:23,  7.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:32:20,841 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856741.7452528, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:21 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:21,877 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:21,879 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:21,880 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:22 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:22,374 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856743.9388194, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:24 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:24,132 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:24,134 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:24,135 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:24 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:24,149 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856745.324916, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:25 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:25,417 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:25 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:25,419 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:25 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:25,420 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.75 / 6 (29.2%):  75%|███████▌  | 6/8 [00:39<00:13,  6.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:25 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:25,942 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856746.883488, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:26 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:26,998 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:26,999 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:27 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:27,001 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:27 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:27,626 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856748.6356702, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:28 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:28,736 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:28,738 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:28,739 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:28 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:28,759 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856749.9743671, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:30 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:30,068 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:30,070 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:30,071 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.25 / 7 (32.2%):  88%|████████▊ | 7/8 [00:43<00:06,  6.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:30 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:30,449 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856751.700887, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:31 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:31,793 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:31,795 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:31,796 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:32 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:32,194 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856753.5635736, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:33 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:33,715 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:33 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:33,717 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:33 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:33,719 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:34,015 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856755.4937153, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:35 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:35,586 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:35 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:35,588 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:35 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:35,589 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:35 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:35,602 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856756.78793, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:36,879 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:36,881 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:36,883 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.92 / 8 (36.5%): 100%|██████████| 8/8 [00:50<00:00,  6.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:32:37 INFO dspy.evaluate.evaluate: Average Metric: 2.9205128205128204 / 8 (36.5%)\n",
      "2025/06/02 11:32:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 36.51 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 4'].\n",
      "2025/06/02 11:32:37 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51]\n",
      "2025/06/02 11:32:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:32:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:32:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:37 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:37,565 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856758.651145, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:38 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:38,774 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:38 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:38,776 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:38 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:38,778 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  12%|█▎        | 1/8 [00:02<00:20,  2.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:40 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:40,366 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856761.720585, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:41 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:41,845 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:41,847 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:41,849 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 2 (50.0%):  25%|██▌       | 2/8 [00:05<00:16,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:43 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:43,132 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856764.2730396, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:44 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:44,404 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:44,406 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:44,408 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 3 (33.3%):  38%|███▊      | 3/8 [00:07<00:12,  2.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:44 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:44,941 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856765.8486986, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:45 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:45,944 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:45 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:45,945 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:45 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:45,947 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.00 / 4 (25.0%):  50%|█████     | 4/8 [00:09<00:08,  2.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:47 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:47,679 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856770.0235488, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:50 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:50,140 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:50,142 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:50,144 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.15 / 5 (23.1%):  62%|██████▎   | 5/8 [00:15<00:10,  3.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:53 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:53,160 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856774.2048864, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:54 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:54,338 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:54,340 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:54,341 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.65 / 6 (27.6%):  75%|███████▌  | 6/8 [00:17<00:06,  3.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:55 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:55,483 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856776.8120465, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:57 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:57,001 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:57 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:57,003 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:57 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:57,005 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.15 / 7 (30.8%):  88%|████████▊ | 7/8 [00:20<00:02,  2.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:57 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:57,982 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856778.9142437, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:32:59 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:32:59,005 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:32:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:59,007 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:32:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:32:59,008 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.82 / 8 (35.3%): 100%|██████████| 8/8 [00:22<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:32:59 INFO dspy.evaluate.evaluate: Average Metric: 2.8205128205128203 / 8 (35.3%)\n",
      "2025/06/02 11:32:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 35.26 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/06/02 11:32:59 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26]\n",
      "2025/06/02 11:32:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:32:59 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:32:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:32:59 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:32:59,687 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856780.768687, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:00 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:00,860 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:00,863 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:00,865 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 1 (44.4%):  12%|█▎        | 1/8 [00:02<00:17,  2.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:02 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:02,269 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856783.5421374, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:03 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:03,656 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:03,658 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:03,660 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 2 (22.2%):  25%|██▌       | 2/8 [00:05<00:18,  3.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:05 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:05,323 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856786.8503308, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:06 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:06,943 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:06,945 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:06,952 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 3 (14.8%):  38%|███▊      | 3/8 [00:08<00:13,  2.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:07 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:07,506 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856789.0247521, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:09 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:09,186 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:09,188 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:09,190 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:33:09 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Cerro Prieto is located in Mexico.', 'turtle_string': '<http://www.wikidata.org/entity/Q5064965> <http://www.wikidata.org/entity/P17> <http://www.wikidata.org/entity/Q96> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q5064965 wdt:P131 wd:Q96 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 3 (14.8%):  50%|█████     | 4/8 [00:10<00:09,  2.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:10 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:10,124 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856791.5939777, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:11 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:11,686 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:11,688 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:11,689 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:19,498 - ERROR - Error executing query on dataset wikidata_predicates: <urlopen error [Errno 60] Operation timed out>\n",
      "2025/06/02 11:33:19 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Swedish Open Cultural Heritage is a project developed by the Swedish National Heritage Board, which is mainly focused on cultural heritage. It produces Resource Description Framework as its product or material and uses XML, JSON, and JSON-LD as its file formats. XML was inspired by Standard Generalized Markup Language.', 'turtle_string': '<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2115> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2063> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P921> <http://www.wikidata.org/entity/Q210272> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P178> <http://www.wikidata.org/entity/Q631844> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q54872> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q6108942> .\\n<http://www.wikidata.org/entity/Q2115> <http://www.wikidata.org/entity/P941> <http://www.wikidata.org/entity/Q207819> .'}) (input_keys={'text'}): <urlopen error [Errno 60] Operation timed out>. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.44 / 3 (14.8%):  62%|██████▎   | 5/8 [00:20<00:15,  5.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:19 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:19,973 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856802.038567, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:22 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:22,188 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:22 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:22,188 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:22 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:22,189 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.94 / 4 (23.6%):  75%|███████▌  | 6/8 [00:25<00:10,  5.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:24 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:24,848 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856805.9397035, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:26 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:26,083 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:26,085 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:26,086 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.52 / 5 (30.3%):  88%|████████▊ | 7/8 [00:27<00:04,  4.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:26 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:26,944 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856808.3388472, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:28 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:28,430 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:28,432 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:28,434 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:33:28 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Abhishek Pictures is a film production company based in Hyderabad.', 'turtle_string': '<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q11424> .\\n<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P159> <http://www.wikidata.org/entity/Q1361> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 4 of <>:\n",
      "Bad syntax (Prefix \"wdtn:\" not bound) at ^ in:\n",
      "\"...b'wdt: <http://www.wikidata.org/prop/direct/> .\\n\\nwd:Q27958422 '^b'wdtn:P31 wd:Q4830453 .\\nwd:Q27958422 wdt:P159 wd:Q1361 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.52 / 5 (30.3%): 100%|██████████| 8/8 [00:29<00:00,  3.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:33:28 INFO dspy.evaluate.evaluate: Average Metric: 1.5158730158730158 / 8 (18.9%)\n",
      "2025/06/02 11:33:28 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 18.95 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 11:33:28 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95]\n",
      "2025/06/02 11:33:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:33:28 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:33:28 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:28 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:28,983 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856810.1854022, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:30 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:30,279 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:30,280 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:30,281 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.33 / 1 (33.3%):  12%|█▎        | 1/8 [00:03<00:23,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:32 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:32,320 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856813.6928833, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:33 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:33,782 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:33 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:33,783 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:33 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:33,785 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.78 / 2 (38.9%):  25%|██▌       | 2/8 [00:05<00:17,  2.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:34,647 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856815.8781958, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:36,016 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:36,018 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:36,020 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.78 / 3 (25.9%):  38%|███▊      | 3/8 [00:07<00:12,  2.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:36 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:36,558 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856817.564606, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:37 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:37,656 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:37,658 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:37,660 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.78 / 4 (19.4%):  50%|█████     | 4/8 [00:09<00:08,  2.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:38 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:38,834 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856820.1546934, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:40 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:40,317 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:40 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:40,319 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:40 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:40,320 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.55 / 5 (30.9%):  62%|██████▎   | 5/8 [00:13<00:08,  2.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:42 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:42,847 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856824.043091, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:44 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:44,212 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:44,214 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:44 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:44,216 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.05 / 6 (34.1%):  75%|███████▌  | 6/8 [00:16<00:05,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:45 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:45,207 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856826.5865834, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:46 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:46,767 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:46,769 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:46,771 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.55 / 7 (36.4%):  88%|████████▊ | 7/8 [00:19<00:02,  2.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:48 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:48,213 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856829.9258091, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:50 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:50,016 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:50,017 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:50,018 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.05 / 8 (38.1%): 100%|██████████| 8/8 [00:21<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:33:50 INFO dspy.evaluate.evaluate: Average Metric: 3.047008547008547 / 8 (38.1%)\n",
      "2025/06/02 11:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 38.09 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 1'].\n",
      "2025/06/02 11:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09]\n",
      "2025/06/02 11:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:33:50 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:50,394 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856831.8306289, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:51 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:51,994 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:51,996 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:51,997 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:52 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:52,032 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856832.8595414, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:53 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:53,012 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:53,014 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:53,015 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:53 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:53,038 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856834.0284944, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:54 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:54,142 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:54,144 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:54,145 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:54 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:54,169 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856835.4826512, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:55 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:55,573 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:55,574 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:55 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:55,576 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:55 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:55,601 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856836.8087833, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:57 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:57,007 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:57 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:57,008 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:57 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:57,010 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:57 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:57,033 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856838.2726557, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:58 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:58,365 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:58,367 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:58,369 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:33:58 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The Ruger Bearcat is a Trigger (firearms) manufactured by Sturm, Ruger & Co. in the United States. It uses .22 Long Rifle rimfire ammunition, which is different from .22 Long.', 'turtle_string': '<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P739> <http://www.wikidata.org/entity/Q158715> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q336751> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P495> <http://www.wikidata.org/entity/Q30> .\\n<http://www.wikidata.org/entity/Q7378530> <http://www.wikidata.org/entity/P176> <http://www.wikidata.org/entity/Q1508526> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q1289462> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P1889> <http://www.wikidata.org/entity/Q1056993> .\\n<http://www.wikidata.org/entity/Q158715> <http://www.wikidata.org/entity/P495> <http://www.wikidata.org/entity/Q30> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'Given the errors and the inability to correctly utilize the '...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n",
      "\u001B[92m11:33:58 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):   0%|          | 0/8 [00:07<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:33:58,384 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  12%|█▎        | 1/8 [00:07<00:55,  8.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856839.4066753, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:33:59 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:33:59,568 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:33:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:59,570 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:33:59,572 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:33:59 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:33:59,593 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856840.4709632, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:00 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:00,592 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:00,594 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:00,596 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:00 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:00,618 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856841.7965765, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:01 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:01,887 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:01,889 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:01,891 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:01 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:01,910 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856843.7204044, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:03 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:03,813 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:03,815 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:03 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:03,816 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:03 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:03,830 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856845.7112591, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:05 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:05,814 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:05,816 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:05,817 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:34:05 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The 2003 Triple J Hottest 100 was determined by the Triple J Hottest 100. It followed the 2002 edition and was followed by the 2004 edition. It is an instance of a record chart.', 'turtle_string': '<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P459> <http://www.wikidata.org/entity/Q17036134> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P155> <http://www.wikidata.org/entity/Q7843427> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P156> <http://www.wikidata.org/entity/Q7843429> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q373899> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'Given the inability to correctly identify and utilize the `u'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  25%|██▌       | 2/8 [00:15<00:46,  7.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:34:05 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:05,841 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856846.7228308, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:06 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:06,839 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:06,841 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:06,842 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:06 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:06,863 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856847.749729, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:07 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:07,843 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:07,845 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:07,846 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:07 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:07,858 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856848.7130349, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:08 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:08,886 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:08,887 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:08,889 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:08 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:08,911 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856849.8598142, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:09 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:09,951 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:09,954 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:09,957 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:09 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:09,982 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856851.054529, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:11 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:11,242 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:11,243 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:11,245 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:11 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:11,262 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856852.6734304, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:12 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:12,776 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:12,779 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:12,785 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:34:12 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The NHL Stadium Series is a sport that consists of ice hockey.', 'turtle_string': '<http://www.wikidata.org/entity/Q17487840> <http://www.wikidata.org/entity/P641> <http://www.wikidata.org/entity/Q41466> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:NHL_Stadium_Series wd:consists_of wd:ice_hockey .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  25%|██▌       | 2/8 [00:22<00:46,  7.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:34:12 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  38%|███▊      | 3/8 [00:22<00:36,  7.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:34:12,801 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856854.0351636, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:14,212 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:14,213 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:14,215 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:14 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:14,225 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856855.3828876, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:15 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:15,474 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:15,476 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:15,478 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:15 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:15,491 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856856.8252118, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:16 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:16,976 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:16,978 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:16,979 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:16 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:16,992 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856858.0609925, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:18 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:18,153 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:18,155 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:18,157 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:18 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:18,170 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856859.6612854, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:19 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:19,752 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:19 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:19,754 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:19 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:19,756 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:34:19 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Cerro Prieto is located in Mexico.', 'turtle_string': '<http://www.wikidata.org/entity/Q5064965> <http://www.wikidata.org/entity/P17> <http://www.wikidata.org/entity/Q96> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'Given the inability to successfully utilize the `uri_search_'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n",
      "\u001B[92m11:34:19 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  38%|███▊      | 3/8 [00:29<00:36,  7.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:34:19,770 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  50%|█████     | 4/8 [00:29<00:28,  7.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856860.9584696, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:21 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:21,073 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:21,074 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:21,076 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:21 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:21,087 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856862.3872292, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:22 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:22,507 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:22 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:22,508 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:22 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:22,510 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:22 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:22,523 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856863.6111362, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:23 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:23,736 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:23,737 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:23,739 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:23 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:23,758 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856864.766965, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:24 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:24,858 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:24,859 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:24 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:24,860 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:24 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:24,878 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856866.0545733, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:26 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:26,295 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:26,296 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:26 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:26,298 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:26 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:26,313 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856867.713128, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:27 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:27,827 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:27 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:27,828 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:27 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:27,829 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:34:27 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Swedish Open Cultural Heritage is a project developed by the Swedish National Heritage Board, which is mainly focused on cultural heritage. It produces Resource Description Framework as its product or material and uses XML, JSON, and JSON-LD as its file formats. XML was inspired by Standard Generalized Markup Language.', 'turtle_string': '<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2115> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q2063> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P921> <http://www.wikidata.org/entity/Q210272> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P178> <http://www.wikidata.org/entity/Q631844> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q54872> .\\n<http://www.wikidata.org/entity/Q7654799> <http://www.wikidata.org/entity/P2701> <http://www.wikidata.org/entity/Q6108942> .\\n<http://www.wikidata.org/entity/Q2115> <http://www.wikidata.org/entity/P941> <http://www.wikidata.org/entity/Q207819> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'Given the errors and the inability to correctly utilize the '...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  50%|█████     | 4/8 [00:37<00:28,  7.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:34:27 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  62%|██████▎   | 5/8 [00:37<00:22,  7.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:34:27,840 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856868.726948, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:28 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:28,819 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:28,821 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:28 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:28,822 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:28 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:28,839 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856870.0900378, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:30 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:30,182 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:30,184 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:30 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:30,187 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:30 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:30,202 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856871.1446872, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:31 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:31,313 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:31,314 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:31 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:31,316 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:31 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:31,328 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856872.209748, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:32 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:32,334 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:32,336 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:32,338 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:32 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:32,351 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856874.4121838, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:34 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:34,504 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:34,506 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:34,507 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:34,523 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856876.5557623, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:36,740 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:36,741 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:36,743 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:34:36 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Vettaikaaran (2009 film) was originally written in the Tamil language, with B. Babusivan as the screenwriter.', 'turtle_string': '<http://www.wikidata.org/entity/Q3531049> <http://www.wikidata.org/entity/P364> <http://www.wikidata.org/entity/Q5885> .\\n<http://www.wikidata.org/entity/Q3531049> <http://www.wikidata.org/entity/P58> <http://www.wikidata.org/entity/Q25553837> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\nwd:Q7942659 wdt:P31 wd:Q11424 .\\nwd:Q7942659 wdt:P5'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n",
      "\u001B[92m11:34:36 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  62%|██████▎   | 5/8 [00:46<00:22,  7.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:34:36,758 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  75%|███████▌  | 6/8 [00:46<00:15,  7.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856877.7424488, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:37 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:37,834 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:37,835 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:37 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:37,837 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:37 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:37,847 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856878.9402647, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:39 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:39,096 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:39,098 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:39 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:39,099 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:39 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:39,111 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856879.972942, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:40 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:40,115 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:40 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:40,116 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:40 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:40,117 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:40 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:40,126 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856881.52819, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:41 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:41,655 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:41,657 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:41,659 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:41 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:41,678 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856883.4815133, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:43 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:43,572 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:43 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:43,574 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:43 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:43,576 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:43 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:43,593 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856886.251365, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:46 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:46,363 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:46,364 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:46,365 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:34:46 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Green economy is a subclass of Environmental economics, which studies the Natural environment and is different from Ecological economics. Environmental economics is itself a subclass of Economics.', 'turtle_string': '<http://www.wikidata.org/entity/Q598188> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q753291> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P2578> <http://www.wikidata.org/entity/Q43619> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P1889> <http://www.wikidata.org/entity/Q1049066> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q8134> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (expected directive or statement) at ^ in:\n",
      "\"b''^b'```turtle\\nwd:Q132240 @prefix wd: <http://www.wikidata.org/en'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n",
      "\u001B[92m11:34:46 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  75%|███████▌  | 6/8 [00:55<00:15,  7.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:34:46,376 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%):  88%|████████▊ | 7/8 [00:55<00:08,  8.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856887.2523339, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:47 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:47,390 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:47 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:47,391 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:47 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:47,392 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:47 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:47,402 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856888.2597084, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:48 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:48,350 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:48,351 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:48 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:48,352 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:48 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:48,363 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856889.305648, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:49 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:49,438 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:49,440 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:49,442 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:49 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:49,457 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856890.3166766, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:50 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:50,463 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:50,465 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:50,467 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:50 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:50,484 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856891.4487107, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:51 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:51,587 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:51,588 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:51,589 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:51 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:51,604 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856892.6320126, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:52 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:52,817 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:52 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:52,819 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:52 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:52,820 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:34:52 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Abhishek Pictures is a film production company based in Hyderabad.', 'turtle_string': '<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P1056> <http://www.wikidata.org/entity/Q11424> .\\n<http://www.wikidata.org/entity/Q27958422> <http://www.wikidata.org/entity/P159> <http://www.wikidata.org/entity/Q1361> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 3 of <>:\n",
      "Bad syntax (Prefix \"rdf:\" not bound) at ^ in:\n",
      "\"...b' wdt: <http://www.wikidata.org/prop/direct/> .\\nwd:Q47452217 '^b'rdf:type wd:Q4830453 ;\\n    wdt:P17 wd:Q1516 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 0 (0%): 100%|██████████| 8/8 [01:02<00:00,  7.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:34:52 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 8 (0.0%)\n",
      "2025/06/02 11:34:52 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 0.0 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 0'].\n",
      "2025/06/02 11:34:52 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0]\n",
      "2025/06/02 11:34:52 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:34:52 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/06/02 11:34:52 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:34:53 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:53,382 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856894.485513, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:54 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:54,660 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:54,662 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:54,663 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.40 / 1 (40.0%):  12%|█▎        | 1/8 [00:03<00:23,  3.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:34:56 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:56,558 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856897.8000333, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:34:57 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:34:57,934 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:34:57 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:57,935 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:34:57 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:34:57,937 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.97 / 2 (48.6%):  25%|██▌       | 2/8 [00:05<00:16,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:34:59 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:34:59,675 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856901.2226048, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:01 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:01,314 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:01,315 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:01,318 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:35:01 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The NHL Stadium Series is a sport that consists of ice hockey.', 'turtle_string': '<http://www.wikidata.org/entity/Q17487840> <http://www.wikidata.org/entity/P641> <http://www.wikidata.org/entity/Q41466> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q17487840 wd:P641 wd:Q41466 .'\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.97 / 2 (48.6%):  38%|███▊      | 3/8 [00:08<00:13,  2.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:01 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:01,625 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856902.6498206, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:02 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:02,751 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:02 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:02,753 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:02 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:02,754 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.97 / 3 (32.4%):  50%|█████     | 4/8 [00:10<00:09,  2.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:05 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:05,489 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856907.753696, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:07 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:07,870 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:07,871 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:07,873 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.14 / 4 (28.5%):  62%|██████▎   | 5/8 [00:17<00:11,  3.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:10 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:10,468 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856911.624067, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:11 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:11,760 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:11,762 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:11,763 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.54 / 5 (30.8%):  75%|███████▌  | 6/8 [00:19<00:06,  3.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:12 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:12,707 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856913.806115, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:13 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:13,897 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:13 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:13,898 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:13 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:13,900 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:35:13 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Green economy is a subclass of Environmental economics, which studies the Natural environment and is different from Ecological economics. Environmental economics is itself a subclass of Economics.', 'turtle_string': '<http://www.wikidata.org/entity/Q598188> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q753291> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P2578> <http://www.wikidata.org/entity/Q43619> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P1889> <http://www.wikidata.org/entity/Q1049066> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q8134> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q598188 wdt:P279 wd:Q753291 .\\nwd:Q753291 wdt:P279 wd:Q813'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.54 / 5 (30.8%):  88%|████████▊ | 7/8 [00:21<00:02,  2.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:14 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:14,530 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856915.9671133, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:16 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:16,063 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:16,065 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:16,066 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.54 / 6 (25.6%): 100%|██████████| 8/8 [00:23<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:35:16 INFO dspy.evaluate.evaluate: Average Metric: 1.5380952380952384 / 8 (19.2%)\n",
      "2025/06/02 11:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 19.23 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 4'].\n",
      "2025/06/02 11:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23]\n",
      "2025/06/02 11:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:35:16 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:17 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:17,403 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856918.5476263, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:18 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:18,725 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:18,727 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:18 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:18,729 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  12%|█▎        | 1/8 [00:03<00:21,  3.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:20 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:20,452 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856921.8715787, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:21 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:21,964 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:21,966 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:21 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:21,967 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:35:21 ERROR dspy.utils.parallelizer: Error for Example({'text': 'The 2003 Triple J Hottest 100 was determined by the Triple J Hottest 100. It followed the 2002 edition and was followed by the 2004 edition. It is an instance of a record chart.', 'turtle_string': '<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P459> <http://www.wikidata.org/entity/Q17036134> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P155> <http://www.wikidata.org/entity/Q7843427> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P156> <http://www.wikidata.org/entity/Q7843429> .\\n<http://www.wikidata.org/entity/Q7843428> <http://www.wikidata.org/entity/P31> <http://www.wikidata.org/entity/Q373899> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q7843428 wdt:P31 wd:Q373899 .\\nwd:Q7843427 wdt:P156 wd:Q78'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  25%|██▌       | 2/8 [00:05<00:14,  2.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:22 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:22,273 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856923.7894394, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:23 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:23,948 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:23,950 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:23 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:23,953 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 2 (30.0%):  38%|███▊      | 3/8 [00:07<00:11,  2.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:24 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:24,533 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856925.5703642, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:25 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:25,720 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:25 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:25,722 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:25 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:25,723 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 3 (20.0%):  50%|█████     | 4/8 [00:09<00:08,  2.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:26 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:26,876 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856928.8815737, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:29 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:29,067 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:29 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:29,069 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:29 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:29,070 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.37 / 4 (34.2%):  62%|██████▎   | 5/8 [00:14<00:09,  3.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:31 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:31,720 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856933.9904697, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:34 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:34,082 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:34,083 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:34 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:34,085 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.87 / 5 (37.4%):  75%|███████▌  | 6/8 [00:17<00:06,  3.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:35 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:35,040 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856936.0326097, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:36,131 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:36,133 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:36,135 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025/06/02 11:35:36 ERROR dspy.utils.parallelizer: Error for Example({'text': 'Green economy is a subclass of Environmental economics, which studies the Natural environment and is different from Ecological economics. Environmental economics is itself a subclass of Economics.', 'turtle_string': '<http://www.wikidata.org/entity/Q598188> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q753291> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P2578> <http://www.wikidata.org/entity/Q43619> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P1889> <http://www.wikidata.org/entity/Q1049066> .\\n<http://www.wikidata.org/entity/Q753291> <http://www.wikidata.org/entity/P279> <http://www.wikidata.org/entity/Q8134> .'}) (input_keys={'text'}): Error parsing turtle strings. Predicted error: Error: at line 1 of <>:\n",
      "Bad syntax (Prefix \"wd:\" not bound) at ^ in:\n",
      "\"b''^b'wd:Q598188 wdt:P279 wd:Q753291 .\\nwd:Q753291 wdt:P279 wd:Q813'...\", Ground truth error: Success. Set `provide_traceback=True` for traceback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.87 / 5 (37.4%):  88%|████████▊ | 7/8 [00:19<00:02,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:36 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:36,830 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856938.6001937, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:35:38 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:35:38,691 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:35:38 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:38,692 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:35:38 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:35:38,693 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.37 / 6 (39.5%): 100%|██████████| 8/8 [00:22<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:35:39 INFO dspy.evaluate.evaluate: Average Metric: 2.3692307692307693 / 8 (29.6%)\n",
      "2025/06/02 11:35:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 29.62 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 2'].\n",
      "2025/06/02 11:35:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62]\n",
      "2025/06/02 11:35:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:35:39 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:35:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.31 / 8 (41.4%): 100%|██████████| 8/8 [00:09<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:35:48 INFO dspy.evaluate.evaluate: Average Metric: 3.3136752136752134 / 8 (41.4%)\n",
      "2025/06/02 11:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 41.42 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 11:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42]\n",
      "2025/06/02 11:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:35:48 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.31 / 8 (41.4%): 100%|██████████| 8/8 [00:09<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:35:58 INFO dspy.evaluate.evaluate: Average Metric: 3.3136752136752134 / 8 (41.4%)\n",
      "2025/06/02 11:35:58 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 41.42 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5', 'Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 11:35:58 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42]\n",
      "2025/06/02 11:35:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 41.42\n",
      "2025/06/02 11:35:58 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:35:58 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:35:58 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:35:58,868 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856960.700664, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:00 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:00,812 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:00,813 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:00 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:00,815 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  12%|█▎        | 1/8 [00:03<00:25,  3.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:02 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:02,506 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856963.9720287, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:04 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:04,086 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:04 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:04,088 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:04 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:04,090 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.04 / 2 (52.2%):  25%|██▌       | 2/8 [00:06<00:18,  3.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:04 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:04,919 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856965.989722, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:06 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:06,132 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:06,132 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:06 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:06,133 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.04 / 3 (34.8%):  38%|███▊      | 3/8 [00:07<00:12,  2.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:06 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:06,646 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856967.7105756, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:07 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:07,877 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:07,878 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:07 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:07,880 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.04 / 4 (26.1%):  50%|█████     | 4/8 [00:09<00:08,  2.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:09 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:09,002 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856970.7262154, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:10 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:10,844 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:10,845 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:10 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:10,846 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.81 / 5 (36.3%):  62%|██████▎   | 5/8 [00:14<00:09,  3.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:13 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:13,322 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856974.721513, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:14,813 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:14,814 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:14,816 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.31 / 6 (38.6%):  75%|███████▌  | 6/8 [00:16<00:05,  2.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:15 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:15,739 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856976.8056304, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:16 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:16,897 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:16,899 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:16 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:16,901 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.89 / 7 (41.2%):  88%|████████▊ | 7/8 [00:18<00:02,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:17 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:17,991 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748856979.1608272, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:19 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:19,252 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:19 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:19,254 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:19 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:19,257 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.39 / 8 (42.3%): 100%|██████████| 8/8 [00:21<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:36:19 INFO dspy.evaluate.evaluate: Average Metric: 3.385103785103785 / 8 (42.3%)\n",
      "2025/06/02 11:36:19 INFO dspy.teleprompt.mipro_optimizer_v2: \u001B[92mBest full score so far!\u001B[0m Score: 42.31\n",
      "2025/06/02 11:36:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.31 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 11:36:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31]\n",
      "2025/06/02 11:36:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:36:19 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:36:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.39 / 8 (42.3%): 100%|██████████| 8/8 [00:09<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:36:28 INFO dspy.evaluate.evaluate: Average Metric: 3.385103785103785 / 8 (42.3%)\n",
      "2025/06/02 11:36:28 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.31 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/06/02 11:36:28 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31, 42.31]\n",
      "2025/06/02 11:36:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:36:28 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:36:28 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.39 / 8 (42.3%): 100%|██████████| 8/8 [00:09<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:36:38 INFO dspy.evaluate.evaluate: Average Metric: 3.385103785103785 / 8 (42.3%)\n",
      "2025/06/02 11:36:38 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.31 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/06/02 11:36:38 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31, 42.31, 42.31]\n",
      "2025/06/02 11:36:38 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:36:38 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:36:38 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.39 / 8 (42.3%): 100%|██████████| 8/8 [00:09<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:36:47 INFO dspy.evaluate.evaluate: Average Metric: 3.385103785103785 / 8 (42.3%)\n",
      "2025/06/02 11:36:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.31 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 11:36:47 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31, 42.31, 42.31, 42.31]\n",
      "2025/06/02 11:36:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:36:47 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:36:47 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:48 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:48,448 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857010.589, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:50 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:50,679 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:50,681 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:50 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:50,682 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  12%|█▎        | 1/8 [00:03<00:26,  3.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:52 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:52,273 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857014.168101, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:54 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:54,262 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:54,264 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:54 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:54,267 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.17 / 2 (58.6%):  25%|██▌       | 2/8 [00:06<00:20,  3.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:55 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:55,156 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857016.1492012, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:56 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:56,241 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:56,242 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:56,244 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.17 / 3 (39.0%):  38%|███▊      | 3/8 [00:08<00:12,  2.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:56 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:56,782 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857018.1140072, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:36:58 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:36:58,207 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:36:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:58,209 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:36:58 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:36:58,210 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.17 / 4 (29.3%):  50%|█████     | 4/8 [00:10<00:09,  2.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:36:59 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:36:59,348 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857021.4806614, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:01 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:01,573 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:01,576 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:01,578 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.46 / 5 (29.1%):  62%|██████▎   | 5/8 [00:16<00:10,  3.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:04 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:04,510 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857025.8322532, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:05 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:05,924 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:05,925 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:05,927 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.96 / 6 (32.6%):  75%|███████▌  | 6/8 [00:18<00:06,  3.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:07 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:07,221 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857028.4299784, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:08 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:08,521 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:08,523 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:08 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:08,526 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.46 / 7 (35.1%):  88%|████████▊ | 7/8 [00:21<00:02,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:09 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:09,765 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857031.0984633, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:11 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:11,191 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:11,194 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:11 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:11,196 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.96 / 8 (37.0%): 100%|██████████| 8/8 [00:23<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:37:11 INFO dspy.evaluate.evaluate: Average Metric: 2.9571428571428573 / 8 (37.0%)\n",
      "2025/06/02 11:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 36.96 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 3'].\n",
      "2025/06/02 11:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31, 42.31, 42.31, 42.31, 36.96]\n",
      "2025/06/02 11:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.39 / 8 (42.3%): 100%|██████████| 8/8 [00:13<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:37:25 INFO dspy.evaluate.evaluate: Average Metric: 3.385103785103785 / 8 (42.3%)\n",
      "2025/06/02 11:37:25 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 42.31 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 2', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 4'].\n",
      "2025/06/02 11:37:25 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31, 42.31, 42.31, 42.31, 36.96, 42.31]\n",
      "2025/06/02 11:37:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:37:25 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:37:25 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 20 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:26 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:26,024 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857047.5944734, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:27 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:27,687 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:27 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:27,689 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:27 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:27,690 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.50 / 1 (50.0%):  12%|█▎        | 1/8 [00:05<00:36,  5.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:31 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:31,176 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857052.4766066, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:32 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:32,617 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:32,619 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:32 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:32,622 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.72 / 2 (36.1%):  25%|██▌       | 2/8 [00:08<00:23,  3.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:34,014 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857055.2284577, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:35 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:35,322 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:35 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:35,323 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:35 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:35,325 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.72 / 3 (24.1%):  38%|███▊      | 3/8 [00:10<00:15,  3.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:35 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:35,965 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857056.878332, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:36,969 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:36,971 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:36,973 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.72 / 4 (18.1%):  50%|█████     | 4/8 [00:11<00:10,  2.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:38 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:38,810 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857061.1369522, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:41 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:41,229 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:41,231 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:41,232 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.88 / 5 (17.5%):  62%|██████▎   | 5/8 [00:18<00:11,  3.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:44 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:44,420 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857066.383976, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:46 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:46,473 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:46,474 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:46 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:46,475 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.38 / 6 (22.9%):  75%|███████▌  | 6/8 [00:21<00:07,  3.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:47 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:47,661 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857069.1972325, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:49 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:49,356 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:49,358 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:49 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:49,360 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.95 / 7 (27.8%):  88%|████████▊ | 7/8 [00:24<00:03,  3.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:50 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:50,307 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857071.3944004, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:51 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:51,485 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:51,487 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:51 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:51,490 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.61 / 8 (32.7%): 100%|██████████| 8/8 [00:26<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:37:51 INFO dspy.evaluate.evaluate: Average Metric: 2.614163614163614 / 8 (32.7%)\n",
      "2025/06/02 11:37:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 32.68 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 3', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 1'].\n",
      "2025/06/02 11:37:51 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31, 42.31, 42.31, 42.31, 36.96, 42.31, 32.68]\n",
      "2025/06/02 11:37:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:37:51 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:37:51 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 20 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:52 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:52,184 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857073.7397316, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:53 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:53,830 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:53,831 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:53 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:53,833 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.60 / 1 (60.0%):  12%|█▎        | 1/8 [00:03<00:22,  3.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:55 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:55,368 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857076.6024218, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:56 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:56,694 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:56,696 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:56 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:56,697 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.46 / 2 (72.9%):  25%|██▌       | 2/8 [00:05<00:16,  2.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:57 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:57,904 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857079.2034304, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:37:59 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:37:59,391 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:37:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:59,393 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:37:59 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:37:59,395 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.46 / 3 (48.6%):  38%|███▊      | 3/8 [00:08<00:12,  2.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:37:59 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:37:59,933 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857081.3615944, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:38:01 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:38:01,507 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:38:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:01,509 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:38:01 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:01,511 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.46 / 4 (36.4%):  50%|█████     | 4/8 [00:10<00:09,  2.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:38:03 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:38:03,225 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857085.2951224, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:38:05 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:38:05,432 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:38:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:05,434 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:38:05 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:05,436 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.61 / 5 (32.2%):  62%|██████▎   | 5/8 [00:16<00:11,  3.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:38:08 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:38:08,243 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857089.8663738, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:38:09 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:38:09,959 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:38:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:09,961 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:38:09 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:09,964 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.11 / 6 (35.2%):  75%|███████▌  | 6/8 [00:18<00:06,  3.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:38:11 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:38:11,029 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857092.1011713, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:38:12 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:38:12,192 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:38:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:12,194 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:38:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:12,195 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.68 / 7 (38.3%):  88%|████████▊ | 7/8 [00:20<00:02,  2.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m11:38:13 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 11:38:13,119 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748857094.103575, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m11:38:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 11:38:14,195 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m11:38:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:14,196 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m11:38:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 11:38:14,198 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.35 / 8 (41.9%): 100%|██████████| 8/8 [00:22<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 11:38:14 INFO dspy.evaluate.evaluate: Average Metric: 3.3490842490842487 / 8 (41.9%)\n",
      "2025/06/02 11:38:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 41.86 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4', 'Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 5'].\n",
      "2025/06/02 11:38:14 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [7.64, 6.25, 41.42, 7.14, 36.51, 35.26, 18.95, 38.09, 0.0, 19.23, 29.62, 41.42, 41.42, 42.31, 42.31, 42.31, 42.31, 36.96, 42.31, 32.68, 41.86]\n",
      "2025/06/02 11:38:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 42.31\n",
      "2025/06/02 11:38:14 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/06/02 11:38:14 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 42.31!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T10:48:42.635241Z",
     "start_time": "2025-06-02T10:48:33.994895Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dd1b04229284268c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m12:48:34 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 12:48:34,019 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748861316.237576, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m12:48:36 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 12:48:36,273 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m12:48:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 12:48:36,274 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m12:48:36 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 12:48:36,275 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m12:48:39 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 12:48:39,920 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748861321.1966412, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m12:48:41 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 12:48:41,292 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m12:48:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 12:48:41,293 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m12:48:41 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 12:48:41,295 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m12:48:41 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 12:48:41,306 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748861322.536859, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m12:48:42 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 12:48:42,621 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m12:48:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 12:48:42,622 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m12:48:42 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 12:48:42,626 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    trajectory={'thought_0': 'To extract triples from the given text and map them onto the underlying knowledge graph, we first need to identify key entities and their relationships. The text mentions \"The General Administration of Quality Supervision, Inspection and Quarantine,\" \"the State Administration for Market Regulation,\" and \"the State Council of the People\\'s Republic of China\" as entities. It also mentions the relationship between these entities, such as one being replaced by another and their hierarchical structure. We need to find URIs for these entities and possibly for the relationship types (e.g., \"replaced by,\" \"parent organization\") in the knowledge graph.', 'tool_name_0': 'uri_search_tool', 'tool_args_0': {'search_terms': ['General Administration of Quality Supervision, Inspection and Quarantine', 'State Administration for Market Regulation', \"State Council of the People's Republic of China\", 'replaced by', 'parent organization']}, 'observation_0': 'Most Similar Search Results for \"General Administration of Quality Supervision, Inspection and Quarantine\" - Default Search Mode (LABEL):\\n  1. Label: General_Administration_of_Quality_Supervision,_Inspection_and_Quarantine\\n     URI: http://www.wikidata.org/entity/Q18020434\\n     Description: predecessor of the State Administration for Market Regulation\\n  2. Label: State_Administration_for_Market_Regulation\\n     URI: http://www.wikidata.org/entity/Q50839256\\n     Description: ministry-level executive agency, under direct authority of the State Council of the People\\'s Republic of China\\n  3. Label: Standard_Generalized_Markup_Language\\n     URI: http://www.wikidata.org/entity/Q207819\\n     Description: markup language\\n\\nMost Similar Search Results for \"State Administration for Market Regulation\" - Default Search Mode (LABEL):\\n  1. Label: State_Administration_for_Market_Regulation\\n     URI: http://www.wikidata.org/entity/Q50839256\\n     Description: ministry-level executive agency, under direct authority of the State Council of the People\\'s Republic of China\\n  2. Label: Government_agency\\n     URI: http://www.wikidata.org/entity/Q327333\\n     Description: organisational part of a government responsible for specific public services, such as health, judiciary, education, transportation, foreign affairs, etc\\n  3. Label: General_Administration_of_Quality_Supervision,_Inspection_and_Quarantine\\n     URI: http://www.wikidata.org/entity/Q18020434\\n     Description: predecessor of the State Administration for Market Regulation\\n\\nMost Similar Search Results for \"State Council of the People\\'s Republic of China\" - Default Search Mode (LABEL):\\n  1. Label: State_Council_of_the_People\\'s_Republic_of_China\\n     URI: http://www.wikidata.org/entity/Q59261\\n     Description: chief administrative authority of the People\\'s Republic of China\\n  2. Label: China\\n     URI: http://www.wikidata.org/entity/Q148\\n     Description: country in East Asia\\n  3. Label: Government_of_Russia\\n     URI: http://www.wikidata.org/entity/Q1140115\\n     Description: highest federal executive body in the Russian Federation, headed by the Prime Minister\\n\\nMost Similar Search Results for \"replaced by\" - Default Search Mode (LABEL):\\n  1. Label: replaced by\\n     URI: http://www.wikidata.org/entity/P1366\\n     Description: other person or item which continues the item by replacing it in its role. Use P156 (\"followed by\") if the item is not replaced nor identical, but adds to the series (e.g. books in a series).\\n  2. Label: used by\\n     URI: http://www.wikidata.org/entity/P1535\\n     Description: item or concept that makes use of the subject (use sub-properties when appropriate)\\n  3. Label: different from\\n     URI: http://www.wikidata.org/entity/P1889\\n     Description: item that is different from another item, with which it may be confused\\n\\nMost Similar Search Results for \"parent organization\" - Default Search Mode (LABEL):\\n  1. Label: parent organization\\n     URI: http://www.wikidata.org/entity/P749\\n     Description: parent organization of an organization, opposite of subsidiaries (P355)\\n  2. Label: organizer\\n     URI: http://www.wikidata.org/entity/P664\\n     Description: person or institution organizing an event\\n  3. Label: chief operating officer\\n     URI: http://www.wikidata.org/entity/P1789\\n     Description: the chief operating officer of an organization\\n\\n', 'thought_1': 'We have found the URIs for the entities mentioned in the text: \"General Administration of Quality Supervision, Inspection and Quarantine\" (http://www.wikidata.org/entity/Q18020434), \"State Administration for Market Regulation\" (http://www.wikidata.org/entity/Q50839256), and \"State Council of the People\\'s Republic of China\" (http://www.wikidata.org/entity/Q59261). We also found the URIs for the relationship types \"replaced by\" (http://www.wikidata.org/entity/P1366) and \"parent organization\" (http://www.wikidata.org/entity/P749). Now, we can use these URIs to create triples representing the relationships between these entities as described in the text.', 'tool_name_1': 'finish', 'tool_args_1': {'triples': [{'subject': 'http://www.wikidata.org/entity/Q18020434', 'predicate': 'http://www.wikidata.org/entity/P1366', 'object': 'http://www.wikidata.org/entity/Q50839256'}, {'subject': 'http://www.wikidata.org/entity/Q50839256', 'predicate': 'http://www.wikidata.org/entity/P749', 'object': 'http://www.wikidata.org/entity/Q59261'}]}, 'observation_1': 'Execution error in finish: \\nTraceback (most recent call last):\\n  File \"/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/dspy/predict/react.py\", line 88, in forward\\n    trajectory[f\"observation_{idx}\"] = self.tools[pred.next_tool_name](**pred.next_tool_args)\\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\\n    return fn(instance, *args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/dspy/primitives/tool.py\", line 143, in __call__\\n    parsed_kwargs = self._validate_and_parse_args(**kwargs)\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/dspy/primitives/tool.py\", line 119, in _validate_and_parse_args\\n    raise ValueError(f\"Arg {k} is not in the tool\\'s args.\")\\nValueError: Arg triples is not in the tool\\'s args.'},\n",
       "    reasoning='The task involves extracting triples from the given text and mapping them onto the underlying knowledge graph. The text mentions \"The General Administration of Quality Supervision, Inspection and Quarantine,\" \"the State Administration for Market Regulation,\" and \"the State Council of the People\\'s Republic of China\" as entities, along with their relationships such as one being replaced by another and their hierarchical structure. Using the `uri_search_tool`, we found the URIs for these entities and the relationship types \"replaced by\" and \"parent organization.\" With these URIs, we can construct triples representing the relationships between the entities as described in the text.',\n",
       "    turtle_string='<http://www.wikidata.org/entity/Q18020434> <http://www.wikidata.org/entity/P1366> <http://www.wikidata.org/entity/Q50839256> .\\n<http://www.wikidata.org/entity/Q50839256> <http://www.wikidata.org/entity/P749> <http://www.wikidata.org/entity/Q59261> .\\n<http://www.wikidata.org/entity/Q18020434> <http://www.wikidata.org/entity/P749> <http://www.wikidata.org/entity/Q59261> .'\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T11:13:22.406797Z",
     "start_time": "2025-06-02T11:13:09.099543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "evaluation_log = []\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    doc_id = i\n",
    "    text = trainset[i].text\n",
    "    trace_id = \"NONE\"\n",
    "    try:\n",
    "        # noinspection PyTypeChecker\n",
    "        response = optimized_agent(text=text)\n",
    "        turtle_string = response.turtle_string\n",
    "    except Exception as e:\n",
    "        turtle_string = e\n",
    "        response = {\"turtle_string\":e}\n",
    "\n",
    "    evaluation_log.append([doc_id, *compare_turtle_strings(predicted_turtle_string=turtle_string, ground_truth_turtle_string=trainset[i].turtle_string), response[\"turtle_string\"], trace_id])\n",
    "\n",
    "evaluation_log_df = pd.DataFrame(\n",
    "    evaluation_log,\n",
    "    columns=[\n",
    "        \"Doc ID\",\n",
    "        \"Correct Triples\", \"Correct Triples with Parents\", \"Correct Triples with Related\", \"Gold Standard Triples\", \"Total Triples Predicted\",\n",
    "        \"Extracted Subjects\", \"Gold Standard Subjects\", \"Correct Extracted Subjects\",\n",
    "        \"Extracted Predicates\", \"Gold Standard Predicates\", \"Correct Extracted Predicates\",\n",
    "        \"Detected Predicates Doc Parent\", \"Detected Predicates Doc Related\",\n",
    "        \"Correct Pred Predicates Parents\", \"Correct Pred Predicates Related\",\n",
    "        \"Extracted Objects\", \"Gold Standard Objects\", \"Correct Extracted Objects\",\n",
    "        \"Extracted Entities\", \"Gold Standard Entities\", \"Correct Extracted Entities\", \"Result String\", \"Langfuse Trace ID\"\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "id": "a6265eac5b772a58",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:05,  1.28s/it]\u001B[92m13:13:10 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 13:13:10,392 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748862791.9693274, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m13:13:12 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 13:13:12,133 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m13:13:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 13:13:12,134 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m13:13:12 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 13:13:12,138 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m13:13:12 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 13:13:12,769 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748862794.133899, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m13:13:14 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 13:13:14,236 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m13:13:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 13:13:14,237 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m13:13:14 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 13:13:14,240 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m13:13:14 - LiteLLM:INFO\u001B[0m: utils.py:2905 - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "2025-06-02 13:13:14,250 - INFO - \n",
      "LiteLLM completion() model= Meta-Llama-3.3-70B-Instruct; provider = openai\n",
      "/Users/i538914/Documents/Uni/Masterarbeit/CIExMAS/.pyvenv311/lib/python3.11/site-packages/pydantic/main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `int` - serialized value may not be as expected [input_value=1748862795.526031, input_type=float])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "\u001B[92m13:13:15 - LiteLLM:INFO\u001B[0m: utils.py:1211 - Wrapper: Completed Call, calling success_handler\n",
      "2025-06-02 13:13:15,600 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001B[92m13:13:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 13:13:15,601 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "\u001B[92m13:13:15 - LiteLLM:INFO\u001B[0m: cost_calculator.py:655 - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "2025-06-02 13:13:15,603 - INFO - selected model name for cost calculation: openai/Meta-Llama-3.3-70B-Instruct\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.65s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'working_dir'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 35\u001B[0m\n\u001B[1;32m     19\u001B[0m     evaluation_log\u001B[38;5;241m.\u001B[39mappend([doc_id, \u001B[38;5;241m*\u001B[39mcompare_turtle_strings(predicted_turtle_string\u001B[38;5;241m=\u001B[39mturtle_string, ground_truth_turtle_string\u001B[38;5;241m=\u001B[39mtrainset[i]\u001B[38;5;241m.\u001B[39mturtle_string), response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mturtle_string\u001B[39m\u001B[38;5;124m\"\u001B[39m], trace_id])\n\u001B[1;32m     21\u001B[0m evaluation_log_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[1;32m     22\u001B[0m     evaluation_log,\n\u001B[1;32m     23\u001B[0m     columns\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     32\u001B[0m     ]\n\u001B[1;32m     33\u001B[0m )\n\u001B[0;32m---> 35\u001B[0m excel_file_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mrepo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworking_dir\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/approaches/evaluation_logs/One_Agent/train_text-5-evaluation_log-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLLM_MODEL_PROVIDER\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLLM_MODEL_ID\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdatetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.xlsx\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     36\u001B[0m evaluation_log_df\u001B[38;5;241m.\u001B[39mto_excel(excel_file_path, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mjson\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'working_dir'"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T11:14:59.064411Z",
     "start_time": "2025-06-02T11:14:58.417310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "repo = git.Repo(search_parent_directories=True)\n",
    "\n",
    "excel_file_path = f\"{repo.working_dir}/approaches/evaluation_logs/One_Agent/train_text-5-evaluation_log-{os.getenv('LLM_MODEL_PROVIDER')}_{os.getenv('LLM_MODEL_ID').replace('/','-')}-{datetime.now().strftime('%Y-%m-%d-%H%M')}.xlsx\"\n",
    "evaluation_log_df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "\n",
    "log_notes_path = f\"{repo.working_dir}/approaches/evaluation_logs/log_notes.json\"\n",
    "try:\n",
    "    with open(log_notes_path, \"r\") as log_file:\n",
    "        log_notes = json.load(log_file)\n",
    "except FileNotFoundError:\n",
    "    log_notes = {}\n",
    "\n",
    "# Use just the filename, not the full path\n",
    "excel_file_name = os.path.basename(excel_file_path)\n",
    "log_notes[excel_file_name] = {\"short_description\": \"Optimized with DSPy\"}\n",
    "\n",
    "with open(log_notes_path, \"w\") as log_file:\n",
    "    json.dump(log_notes, log_file, indent=4)"
   ],
   "id": "721588e7876c4350",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T11:32:11.541660Z",
     "start_time": "2025-06-02T11:32:11.537596Z"
    }
   },
   "cell_type": "code",
   "source": "optimized_agent.save(f\"{repo.working_dir}/approaches/One_Agent/DSPy Testing/optimized_agent.json\", save_program=False)",
   "id": "e97e5e41d74bbdc7",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4d5693b072b151a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyvenv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
